 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Printing the best bid and the best ask
Feeding the data
Getting the market depth
Submitting an order
Clearing inactive orders (FILLED, CANCELED, EXPIRED)
Watching a order status - pending due to order latency
Waiting for an order response
Printing position, balance, fee, and equity
Canceling an open order
Market order
GTX, Post-Only order
Plotting BBO
Printing stats
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Download Custom Editor Distribute CKEditor with CDN, or self-host with NPM or ZIP options. Start now
Ads by EthicalAds
Close Ad
 Getting StartedView page source
Getting Started
Printing the best bid and the best ask
from numba import njit

import numpy as np

# numba.njit is strongly recommended for fast backtesting.
@njit
def print_bbo(hbt):
    # Iterating until hftbacktest reaches the end of data.
    # Elapses 60-sec every iteration.
    # Time unit is the same as data's timestamp's unit.
    # Timestamp of the sample data is in nanoseconds.
    while hbt.elapse(60 * 1e9) == 0:
        # Gets the market depth for the first asset.
        depth = hbt.depth(0)

        # Prints the best bid and the best offer.
        print(
            'current_timestamp:', hbt.current_timestamp,
            ', best_bid:', np.round(depth.best_bid, 1),
            ', best_ask:', np.round(depth.best_ask, 1)
        )
    return True
from hftbacktest import BacktestAsset, HashMapMarketDepthBacktest

asset = (
    BacktestAsset()
        # Sets the data to feed for this asset.
        #
        # Due to the vast size of tick-by-tick market depth and trade data,
        # loading the entire dataset into memory can be challenging,
        # particularly when backtesting across multiple days.
        # HftBacktest offers lazy loading support and is compatible with npy and preferably npz.
        #
        # For details on the normalized feed data, refer to the following documents.
        # * https://hftbacktest.readthedocs.io/en/latest/data.html
        # * https://hftbacktest.readthedocs.io/en/latest/tutorials/Data%20Preparation.html
        .data(['usdm/btcusdt_20240809.npz'])
        # Sets the initial snapshot (optional).
        .initial_snapshot('usdm/btcusdt_20240808_eod.npz')
        # Asset type:
        # * Linear
        # * Inverse.
        # 1.0 represents the contract size, which is the value of the asset per quoted price.
        .linear_asset(1.0)
        # HftBacktest provides two built-in latency models.
        # * constant_latency
        # * intp_order_latency
        # To implement your own latency model, please use Rust.
        #
        # Time unit is the same as data's timestamp's unit. Timestamp of the sample data is in nanoseconds.
        # Sets the order entry latency and response latency to 10ms.
        .constant_latency(10_000_000, 10_000_000)
        # HftBacktest provides several types of built-in queue position models.
        # Please find the details in the documents below.
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Probability%20Queue%20Models.html
        #
        # To implement your own queue position model, please use Rust.
        .risk_adverse_queue_model()
        # HftBacktest provides two built-in exchange models.
        # * no_partial_fill_exchange
        # * partial_fill_exchange
        # To implement your own exchange model, please use Rust.
        .no_partial_fill_exchange()
        # HftBacktest provides several built-in fee models.
        # * trading_value_fee_model
        # * trading_qty_fee_model
        # * flat_per_trade_fee_model
        #
        # 0.02% maker fee and 0.07% taker fee. If the fee is negative, it represents a rebate.
        # For example, -0.00005 represents a 0.005% rebate for the maker order.
        .trading_value_fee_model(0.0002, 0.0007)
        # Tick size of this asset: minimum price increasement
        .tick_size(0.1)
        # Lot size of this asset: minimum trading unit.
        .lot_size(0.001)
        # Sets the capacity of the vector that stores trades occurring in the market.
        # If you set the size, you need call `clear_last_trades` to clear the vector.
        # A value of 0 indicates that no market trades are stored. (Default)
        .last_trades_capacity(0)
)

# HftBacktest provides several types of built-in market depth implementations.
# HashMapMarketDepthBacktest constructs a Backtest using a HashMap-based market depth implementation.
# Another useful implementation is ROIVectorMarketDepth, which is utilized in ROIVectorMarketDepthBacktest.
# Please find the details in the document below.
hbt = HashMapMarketDepthBacktest([asset])
You can see the best bid and best ask every 60 seconds. Since the price is a 32-bit float, there may be floating-point errors. Be careful when using it. In the example, for readability, the price is rounded based on the tick size.

print_bbo(hbt)
current_timestamp: 1723161661500000000 , best_bid: 61594.1 , best_ask: 61594.2
current_timestamp: 1723161721500000000 , best_bid: 61576.5 , best_ask: 61576.6
current_timestamp: 1723161781500000000 , best_bid: 61629.6 , best_ask: 61629.7
current_timestamp: 1723161841500000000 , best_bid: 61621.5 , best_ask: 61621.6
current_timestamp: 1723161901500000000 , best_bid: 61583.9 , best_ask: 61584.0
True
HftBacktest cannot be reused. Therefore, after using the backtest, make sure to close it. If you use the backtest after closing, it will crash.

_ = hbt.close()
Feeding the data
When you possess adequate memory, preloading the data into memory and providing it as input will be more efficient than lazy-loading during repeated backtesting.

btcusdt_20230809 = np.load('usdm/btcusdt_20240809.npz')['data']
btcusdt_20230808_eod = np.load('usdm/btcusdt_20240808_eod.npz')['data']

asset = (
    BacktestAsset()
        .data([btcusdt_20230809])
        .initial_snapshot(btcusdt_20230808_eod)
        .linear_asset(1.0)
        .constant_latency(10_000_000, 10_000_000)
        .risk_adverse_queue_model()
        .no_partial_fill_exchange()
        .trading_value_fee_model(0.0002, 0.0007)
        .tick_size(0.1)
        .lot_size(0.001)
)
hbt = HashMapMarketDepthBacktest([asset])

print_bbo(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000 , best_bid: 61594.1 , best_ask: 61594.2
current_timestamp: 1723161721500000000 , best_bid: 61576.5 , best_ask: 61576.6
current_timestamp: 1723161781500000000 , best_bid: 61629.6 , best_ask: 61629.7
current_timestamp: 1723161841500000000 , best_bid: 61621.5 , best_ask: 61621.6
current_timestamp: 1723161901500000000 , best_bid: 61583.9 , best_ask: 61584.0
Getting the market depth
@njit
def print_3depth(hbt):
    while hbt.elapse(60 * 1e9) == 0:
        print('current_timestamp:', hbt.current_timestamp)

        # Gets the market depth for the first asset, in the same order as when you created the backtest.
        depth = hbt.depth(0)

        # a key of bid_depth or ask_depth is price in ticks.
        # (integer) price_tick = price / tick_size
        i = 0
        for tick_price in range(depth.best_ask_tick, depth.best_ask_tick + 100):
            qty = depth.ask_qty_at_tick(tick_price)
            if qty > 0:
                print(
                    'ask: ',
                    qty,
                    '@',
                    np.round(tick_price * depth.tick_size, 1)
                )

                i += 1
                if i == 3:
                    break
        i = 0
        for tick_price in range(depth.best_bid_tick, max(depth.best_bid_tick - 100, 0), -1):
            qty = depth.bid_qty_at_tick(tick_price)
            if qty > 0:
                print(
                    'bid: ',
                    qty,
                    '@',
                    np.round(tick_price * depth.tick_size, 1)
                )

                i += 1
                if i == 3:
                    break
    return True
hbt = HashMapMarketDepthBacktest([asset])

print_3depth(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000
ask:  1.759 @ 61594.2
ask:  0.006 @ 61594.4
ask:  0.114 @ 61595.2
bid:  3.526 @ 61594.1
bid:  0.016 @ 61594.0
bid:  0.002 @ 61593.9
current_timestamp: 1723161721500000000
ask:  2.575 @ 61576.6
ask:  0.004 @ 61576.7
ask:  0.455 @ 61577.0
bid:  2.558 @ 61576.5
bid:  0.002 @ 61576.0
bid:  0.515 @ 61575.5
current_timestamp: 1723161781500000000
ask:  0.131 @ 61629.7
ask:  0.005 @ 61630.1
ask:  0.005 @ 61630.5
bid:  5.742 @ 61629.6
bid:  0.247 @ 61629.4
bid:  0.034 @ 61629.3
current_timestamp: 1723161841500000000
ask:  0.202 @ 61621.6
ask:  0.002 @ 61622.5
ask:  0.003 @ 61622.6
bid:  3.488 @ 61621.5
bid:  0.86 @ 61620.0
bid:  0.248 @ 61619.6
current_timestamp: 1723161901500000000
ask:  1.397 @ 61584.0
ask:  0.832 @ 61585.1
ask:  0.132 @ 61586.0
bid:  3.307 @ 61583.9
bid:  0.01 @ 61583.8
bid:  0.002 @ 61582.0
Submitting an order
from hftbacktest import LIMIT, GTC, NONE, NEW, FILLED, CANCELED, EXPIRED

@njit
def print_orders(hbt):
    # You can access open orders and also closed orders via hbt.orders.
    # Gets the OrderDict for the first asset.
    orders = hbt.orders(0)

    # hbt.orders is a dictionary, but be aware that it does not support all dict methods, and its keys are order_id (int).
    order_values = orders.values()
    while order_values.has_next():
        order = order_values.get()

        order_status = ''
        if order.status == NONE:
            order_status = 'NONE' # Exchange hasn't received an order yet.
        elif order.status == NEW:
            order_status = 'NEW'
        elif order.status == FILLED:
            order_status = 'FILLED'
        elif order.status == CANCELED:
            order_status = 'CANCELED'
        elif order.status == EXPIRED:
            order_status = 'EXPIRED'

        order_req = ''
        if order.req == NONE:
            order_req = 'NONE'
        elif order.req == NEW:
            order_req = 'NEW'
        elif order.req == CANCELED:
            order_req = 'CANCEL'

        print(
            'current_timestamp:', hbt.current_timestamp,
             ', order_id:', order.order_id,
             ', order_price:', np.round(order.price, 1),
             ', order_qty:', order.qty,
             ', order_status:', order_status,
             ', order_req:', order_req
        )

@njit
def submit_order(hbt):
    is_order_submitted = False
    while hbt.elapse(30 * 1e9) == 0:
        # Prints open orders.
        print_orders(hbt)

        depth = hbt.depth(0)

        if not is_order_submitted:
            # Submits a buy order at 300 ticks below the best bid for the first asset.
            order_id = 1
            order_price = depth.best_bid - 300 * depth.tick_size
            order_qty = 1
            time_in_force = GTC # Good 'till cancel
            order_type = LIMIT
            hbt.submit_buy_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)
            is_order_submitted = True
    return True
hbt = HashMapMarketDepthBacktest([asset])

submit_order(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161691500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161721500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161751500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161781500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161811500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161841500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161871500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161901500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
Clearing inactive orders (FILLED, CANCELED, EXPIRED)
from hftbacktest import GTC

@njit
def clear_inactive_orders(hbt):
    is_order_submitted = False
    while hbt.elapse(30 * 1e9) == 0:
        print_orders(hbt)

        # Removes inactive(FILLED, CANCELED, EXPIRED) orders from hbt.orders for the first asset.
        hbt.clear_inactive_orders(0)

        depth = hbt.depth(0)

        if not is_order_submitted:
            order_id = 1
            order_price = depth.best_bid - 300 * depth.tick_size
            order_qty = 1
            time_in_force = GTC
            order_type = LIMIT
            hbt.submit_buy_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)
            is_order_submitted = True
    return True
hbt = HashMapMarketDepthBacktest([asset])

clear_inactive_orders(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000 , order_id: 1 , order_price: 61643.8 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
Watching a order status - pending due to order latency
from hftbacktest import GTC

@njit
def watch_pending(hbt):
    is_order_submitted = False
    # Elapses 0.01-sec every iteration.
    while hbt.elapse(0.01 * 1e9) == 0:
        print_orders(hbt)

        hbt.clear_inactive_orders(0)

        depth = hbt.depth(0)

        if not is_order_submitted:
            order_id = 1
            order_price = depth.best_bid - 300 * depth.tick_size
            order_qty = 1
            time_in_force = GTC
            order_type = LIMIT
            hbt.submit_buy_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)
            is_order_submitted = True

        # Prevents too many prints
        orders = hbt.orders(0)
        order = orders.get(order_id)
        if order.status == NEW:
            return False
    return True
The order_status is None until the acceptance message is received.

hbt = HashMapMarketDepthBacktest([asset])

watch_pending(hbt)

_ = hbt.close()
current_timestamp: 1723161601520000000 , order_id: 1 , order_price: 61629.7 , order_qty: 1.0 , order_status: NONE , order_req: NEW
current_timestamp: 1723161601530000000 , order_id: 1 , order_price: 61629.7 , order_qty: 1.0 , order_status: NEW , order_req: NONE
Waiting for an order response
from hftbacktest import GTC

@njit
def wait_for_order_response(hbt):
    order_id = 0
    is_order_submitted = False
    while hbt.elapse(0.01 * 1e9) == 0:
        print_orders(hbt)

        hbt.clear_inactive_orders(0)

        # Prevents too many prints
        orders = hbt.orders(0)
        if order_id in orders:
            if orders.get(order_id).status == NEW:
                return False

        depth = hbt.depth(0)

        if not is_order_submitted:
            order_id = 1
            order_price = depth.best_bid
            order_qty = 1
            time_in_force = GTC
            order_type = LIMIT
            hbt.submit_buy_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)
            # Waits for the order response for a given order id for the first asset.
            print('an order is submitted at', hbt.current_timestamp)

            # Timeout is set 1-second.
            hbt.wait_order_response(0, order_id, 1 * 1e9)
            print('an order response is received at', hbt.current_timestamp)
            is_order_submitted = True
    return True
Since the ConstantLatency model is used, the round-trip latency is exactly 200ms. Ideally, using historical order latency data collected from the live market is the best approach. However, if this data is not available, starting with artificially generated order latency based on feed latency is another option. We will explore this in the following examples.

hbt = HashMapMarketDepthBacktest([asset])

wait_for_order_response(hbt)

_ = hbt.close()
an order is submitted at 1723161601510000000
an order response is received at 1723161601530000000
current_timestamp: 1723161601540000000 , order_id: 1 , order_price: 61659.7 , order_qty: 1.0 , order_status: NEW , order_req: NONE
Printing position, balance, fee, and equity
@njit
def position(hbt):
    is_order_submitted = False
    while hbt.elapse(60 * 1e9) == 0:
        print_orders(hbt)

        hbt.clear_inactive_orders(0)

        # Prints position
        print(
            'current_timestamp:', hbt.current_timestamp,
            ', position:', hbt.position(0),
            ', balance:', hbt.state_values(0).balance,
            ', fee:', hbt.state_values(0).fee
        )

        depth = hbt.depth(0)

        if not is_order_submitted:
            order_id = 1
            order_price = depth.best_bid
            order_qty = 1
            time_in_force = GTC
            order_type = LIMIT
            hbt.submit_buy_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)

            # Timeout is set 1-second.
            hbt.wait_order_response(0, order_id, 1e9)
            is_order_submitted = True
    return True
hbt = HashMapMarketDepthBacktest([asset])

position(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000 , position: 0.0 , balance: 0.0 , fee: 0.0
current_timestamp: 1723161721520000000 , order_id: 1 , order_price: 61594.1 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161721520000000 , position: 1.0 , balance: -61594.100000000006 , fee: 12.318820000000002
current_timestamp: 1723161781520000000 , position: 1.0 , balance: -61594.100000000006 , fee: 12.318820000000002
current_timestamp: 1723161841520000000 , position: 1.0 , balance: -61594.100000000006 , fee: 12.318820000000002
current_timestamp: 1723161901520000000 , position: 1.0 , balance: -61594.100000000006 , fee: 12.318820000000002
Canceling an open order
@njit
def submit_and_cancel_order(hbt):
    is_order_submitted = False
    while hbt.elapse(0.1 * 1e9) == 0:
        print_orders(hbt)

        hbt.clear_inactive_orders(0)

        # Cancels if there is an open order
        orders = hbt.orders(0)
        order_values = orders.values()
        while order_values.has_next():
            order = order_values.get()

            # an order is only cancellable if order status is NEW.
            # cancel request is negated if the order is already filled or filled before cancel request is processed.
            if order.cancellable:
                hbt.cancel(0, order.order_id, False)
                # You can see status still NEW and see req CANCEL.
                print_orders(hbt)
                # cancels request also has order entry/response latencies the same as submitting.
                hbt.wait_order_response(0, order.order_id, 1e9)

        if not is_order_submitted:
            depth = hbt.depth(0)

            order_id = 1
            order_price = depth.best_bid - 100 * depth.tick_size
            order_qty = 1
            time_in_force = GTC
            order_type = LIMIT
            hbt.submit_buy_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)

            # Timeout is set 1-second.
            hbt.wait_order_response(0, order_id, 1e9)
            is_order_submitted = True
        else:
            if len(hbt.orders(0)) == 0:
                return False
    return True
hbt = HashMapMarketDepthBacktest([asset])

submit_and_cancel_order(hbt)

_ = hbt.close()
current_timestamp: 1723161601720000000 , order_id: 1 , order_price: 61649.7 , order_qty: 1.0 , order_status: NEW , order_req: NONE
current_timestamp: 1723161601720000000 , order_id: 1 , order_price: 61649.7 , order_qty: 1.0 , order_status: NEW , order_req: CANCEL
current_timestamp: 1723161601840000000 , order_id: 1 , order_price: 61649.7 , order_qty: 1.0 , order_status: CANCELED , order_req: NONE
Market order
from hftbacktest import MARKET

@njit
def print_orders_exec_price(hbt):
    orders = hbt.orders(0)
    order_values = orders.values()
    while order_values.has_next():
        order = order_values.get()

        order_status = ''
        if order.status == NONE:
            order_status = 'NONE'
        elif order.status == NEW:
            order_status = 'NEW'
        elif order.status == FILLED:
            order_status = 'FILLED'
        elif order.status == CANCELED:
            order_status = 'CANCELED'
        elif order.status == EXPIRED:
            order_status = 'EXPIRED'

        order_req = ''
        if order.req == NONE:
            order_req = 'NONE'
        elif order.req == NEW:
            order_req = 'NEW'
        elif order.req == CANCELED:
            order_req = 'CANCEL'

        print(
            'current_timestamp:', hbt.current_timestamp,
             ', order_id:', order.order_id,
             ', order_price:', np.round(order.price, 1),
             ', order_qty:', order.qty,
             ', order_status:', order_status,
             ', exec_price:', np.round(order.exec_price, 1)
        )

@njit
def market_order(hbt):
    is_order_submitted = False
    while hbt.elapse(60 * 1e9) == 0:
        print_orders(hbt)

        hbt.clear_inactive_orders(0)

        state_values = hbt.state_values(0)

        print(
            'current_timestamp:', hbt.current_timestamp,
             ', position:', hbt.position(0),
             ', balance:', state_values.balance,
             ', fee:', state_values.fee
        )

        if not is_order_submitted:
            depth = hbt.depth(0)

            order_id = 1
            # Sets an arbitrary price, which does not affect MARKET orders.
            order_price = depth.best_bid
            order_qty = 1
            time_in_force = GTC
            order_type = MARKET
            hbt.submit_sell_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)
            hbt.wait_order_response(0, order_id, 1e9)
            # You can see the order immediately filled.
            # Also you can see the order executed at the best bid which is different from what it was submitted at.
            print('best_bid:', depth.best_bid)
            print_orders_exec_price(hbt)
            is_order_submitted = True
    return True
hbt = HashMapMarketDepthBacktest([asset])

market_order(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000 , position: 0.0 , balance: 0.0 , fee: 0.0
best_bid: 61594.100000000006
current_timestamp: 1723161661520000000 , order_id: 1 , order_price: 61594.1 , order_qty: 1.0 , order_status: FILLED , exec_price: 61594.1
current_timestamp: 1723161721520000000 , order_id: 1 , order_price: 61594.1 , order_qty: 1.0 , order_status: FILLED , order_req: NONE
current_timestamp: 1723161721520000000 , position: -1.0 , balance: 61594.100000000006 , fee: 43.11587
current_timestamp: 1723161781520000000 , position: -1.0 , balance: 61594.100000000006 , fee: 43.11587
current_timestamp: 1723161841520000000 , position: -1.0 , balance: 61594.100000000006 , fee: 43.11587
current_timestamp: 1723161901520000000 , position: -1.0 , balance: 61594.100000000006 , fee: 43.11587
GTX, Post-Only order
from hftbacktest import GTX

@njit
def submit_gtx(hbt):
    is_order_submitted = False
    while hbt.elapse(60 * 1e9) == 0:
        print_orders(hbt)

        hbt.clear_inactive_orders(0)

        state_values = hbt.state_values(0)

        print(
            'current_timestamp:', hbt.current_timestamp,
             ', position:', hbt.position(0),
             ', balance:', state_values.balance,
             ', fee:', state_values.fee
        )

        if not is_order_submitted:
            depth = hbt.depth(0)

            order_id = 1
            # Sets a deep price in the opposite side and it will be rejected by GTX.
            order_price = depth.best_bid - 100 * depth.tick_size
            order_qty = 1
            time_in_force = GTX
            order_type = LIMIT
            hbt.submit_sell_order(0, order_id, order_price, order_qty, time_in_force, order_type, False)
            hbt.wait_order_response(0, order_id, 1e9)
            is_order_submitted = True
    return True
hbt = HashMapMarketDepthBacktest([asset])

submit_gtx(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000 , position: 0.0 , balance: 0.0 , fee: 0.0
current_timestamp: 1723161721520000000 , order_id: 1 , order_price: 61584.1 , order_qty: 1.0 , order_status: EXPIRED , order_req: NONE
current_timestamp: 1723161721520000000 , position: 0.0 , balance: 0.0 , fee: 0.0
current_timestamp: 1723161781520000000 , position: 0.0 , balance: 0.0 , fee: 0.0
current_timestamp: 1723161841520000000 , position: 0.0 , balance: 0.0 , fee: 0.0
current_timestamp: 1723161901520000000 , position: 0.0 , balance: 0.0 , fee: 0.0
Plotting BBO
@njit
def plot_bbo(hbt, local_timestamp, best_bid, best_ask):
    while hbt.elapse(1 * 1e9) == 0:
        # Records data points
        local_timestamp.append(hbt.current_timestamp)

        depth = hbt.depth(0)

        best_bid.append(depth.best_bid)
        best_ask.append(depth.best_ask)
    return True
# Uses Numba list for njit.
from numba.typed import List
from numba import int64, float64

import polars as pl

local_timestamp = List.empty_list(int64, allocated=10000)
best_bid = List.empty_list(float64, allocated=10000)
best_ask = List.empty_list(float64, allocated=10000)

hbt = HashMapMarketDepthBacktest([asset])

plot_bbo(hbt, local_timestamp, best_bid, best_ask)

hbt.close()

df = pl.DataFrame({'timestamp': local_timestamp, 'best_bid': best_bid, 'best_ask': best_ask})
df = df.with_columns(
    pl.from_epoch('timestamp', time_unit='ns')
)

df.plot(x='timestamp')
Printing stats
@njit
def submit_order_stats(hbt, recorder):
    buy_order_id = 1
    sell_order_id = 2
    half_spread = 5 * hbt.depth(0).tick_size

    while hbt.elapse(1 * 1e9) == 0:
        hbt.clear_inactive_orders(0)

        depth = hbt.depth(0)

        mid_price = (depth.best_bid + depth.best_ask) / 2.0

        if buy_order_id not in hbt.orders(0):
            order_price = round((mid_price - half_spread) / depth.tick_size) * depth.tick_size
            order_qty = 1
            time_in_force = GTX
            order_type = LIMIT
            hbt.submit_buy_order(0, buy_order_id, order_price, order_qty, time_in_force, order_type, False)
        else:
            hbt.cancel(0, buy_order_id, False)

        if sell_order_id not in hbt.orders(0):
            order_price = round((mid_price + half_spread) / depth.tick_size) * depth.tick_size
            order_qty = 1
            time_in_force = GTX
            order_type = LIMIT
            hbt.submit_sell_order(0, sell_order_id, order_price, order_qty, time_in_force, order_type, False)
        else:
            hbt.cancel(0, sell_order_id, False)

        recorder.record(hbt)
    return True
from hftbacktest import Recorder

hbt = HashMapMarketDepthBacktest([asset])

recorder = Recorder(
    # The number of assets
    hbt.num_assets,
    # The buffer size for records
    1000000
)

submit_order_stats(hbt, recorder.recorder)

_ = hbt.close()
You can get recorded states using the get method with the asset number.

recorder.get(0)
array([(1723161602500000000, 61659.85,  0.,  0.000000e+00,    0.     ,   0,   0.,        0. ),
       (1723161603500000000, 61659.95,  1., -6.165940e+04,   12.33188,   1,   1.,    61659.4),
       (1723161604500000000, 61670.85,  1., -6.165940e+04,   12.33188,   1,   1.,    61659.4),
       (1723161605500000000, 61692.45,  0.,  1.200000e+01,   24.66616,   2,   2.,   123330.8),
       (1723161606500000000, 61693.95,  0.,  1.300000e+01,   49.34312,   4,   4.,   246715.6),
       (1723161607500000000, 61695.45, -1.,  6.170740e+04,   61.682  ,   5,   5.,   308410. ),
       (1723161608500000000, 61709.95, -2.,  1.234033e+05,   74.02118,   6,   6.,   370105.9),
       (1723161609500000000, 61707.35, -1.,  6.169390e+04,   86.36306,   7,   7.,   431815.3),
       (1723161610500000000, 61715.85, -1.,  6.169390e+04,   86.36306,   7,   7.,   431815.3),
       (1723161611500000000, 61711.85, -2.,  1.234103e+05,   98.70634,   8,   8.,   493531.7),
       (1723161612500000000, 61713.95, -3.,  1.851227e+05,  111.04882,   9,   9.,   555244.1),
       (1723161613500000000, 61706.15, -4.,  2.468371e+05,  123.3917 ,  10,  10.,   616958.5),
       (1723161614500000000, 61708.25, -5.,  3.085437e+05,  135.73302,  11,  11.,   678665.1),
       (1723161615500000000, 61699.75, -6.,  3.702525e+05,  148.07478,  12,  12.,   740373.9),
       (1723161616500000000, 61700.95, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161617500000000, 61698.05, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161618500000000, 61706.95, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161619500000000, 61695.85, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161620500000000, 61713.45, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161621500000000, 61707.65, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161622500000000, 61713.45, -7.,  4.319527e+05,  160.41482,  13,  13.,   802074.1),
       (1723161623500000000, 61704.05, -6.,  3.702455e+05,  172.75626,  14,  14.,   863781.3),
       (1723161624500000000, 61702.45, -5.,  3.085419e+05,  185.09698,  15,  15.,   925484.9),
       (1723161625500000000, 61704.65, -6.,  3.702448e+05,  197.43756,  16,  16.,   987187.8),
       (1723161626500000000, 61704.65, -6.,  3.702448e+05,  197.43756,  16,  16.,   987187.8),
       (1723161627500000000, 61695.35, -5.,  3.085406e+05,  209.7784 ,  17,  17.,  1048892. ),
       (1723161628500000000, 61693.75, -4.,  2.468458e+05,  222.11736,  18,  18.,  1110586.8),
       (1723161629500000000, 61693.75, -4.,  2.468458e+05,  222.11736,  18,  18.,  1110586.8),
       (1723161630500000000, 61682.35, -4.,  2.468458e+05,  222.11736,  18,  18.,  1110586.8),
       (1723161631500000000, 61673.85, -3.,  1.851640e+05,  234.45372,  19,  19.,  1172268.6),
       (1723161632500000000, 61666.05, -2.,  1.234906e+05,  246.7884 ,  20,  20.,  1233942. ),
       (1723161633500000000, 61671.05, -2.,  1.234906e+05,  246.7884 ,  20,  20.,  1233942. ),
       (1723161634500000000, 61673.75, -3.,  1.851622e+05,  259.12272,  21,  21.,  1295613.6),
       (1723161635500000000, 61673.75, -3.,  1.851622e+05,  259.12272,  21,  21.,  1295613.6),
       (1723161636500000000, 61666.05, -3.,  1.851622e+05,  259.12272,  21,  21.,  1295613.6),
       (1723161637500000000, 61670.45, -4.,  2.468288e+05,  271.45604,  22,  22.,  1357280.2),
       (1723161638500000000, 61664.05, -4.,  2.468288e+05,  271.45604,  22,  22.,  1357280.2),
       (1723161639500000000, 61649.05, -3.,  1.851652e+05,  283.78876,  23,  23.,  1418943.8),
       (1723161640500000000, 61645.05, -3.,  1.851652e+05,  283.78876,  23,  23.,  1418943.8),
       (1723161641500000000, 61640.05, -2.,  1.235206e+05,  296.11768,  24,  24.,  1480588.4),
       (1723161642500000000, 61638.45, -1.,  6.188100e+04,  308.4456 ,  25,  25.,  1542228. ),
       (1723161643500000000, 61636.05,  0.,  2.431000e+02,  320.77318,  26,  26.,  1603865.9),
       (1723161644500000000, 61641.95, -1.,  6.187970e+04,  333.1005 ,  27,  27.,  1665502.5),
       (1723161645500000000, 61641.95, -1.,  6.187970e+04,  333.1005 ,  27,  27.,  1665502.5),
       (1723161646500000000, 61644.35, -1.,  6.187970e+04,  333.1005 ,  27,  27.,  1665502.5),
       (1723161647500000000, 61636.45, -1.,  6.187970e+04,  333.1005 ,  27,  27.,  1665502.5),
       (1723161648500000000, 61630.05,  0.,  2.438000e+02,  345.42768,  28,  28.,  1727138.4),
       (1723161649500000000, 61630.05,  0.,  2.438000e+02,  345.42768,  28,  28.,  1727138.4),
       (1723161650500000000, 61631.65,  0.,  2.438000e+02,  345.42768,  28,  28.,  1727138.4),
       (1723161651500000000, 61639.05, -1.,  6.187600e+04,  357.75412,  29,  29.,  1788770.6),
       (1723161652500000000, 61632.05, -1.,  6.187600e+04,  357.75412,  29,  29.,  1788770.6),
       (1723161653500000000, 61633.95, -1.,  6.187600e+04,  357.75412,  29,  29.,  1788770.6),
       (1723161654500000000, 61632.05, -2.,  1.235104e+05,  370.081  ,  30,  30.,  1850405. ),
       (1723161655500000000, 61604.05, -1.,  6.187880e+04,  382.40732,  31,  31.,  1912036.6),
       (1723161656500000000, 61604.05, -1.,  6.187880e+04,  382.40732,  31,  31.,  1912036.6),
       (1723161657500000000, 61607.05, -1.,  6.187880e+04,  382.40732,  31,  31.,  1912036.6),
       (1723161658500000000, 61603.15,  0.,  2.722000e+02,  394.72864,  32,  32.,  1973643.2),
       (1723161659500000000, 61601.15,  1., -6.133040e+04,  407.04916,  33,  33.,  2035245.8),
       (1723161660500000000, 61595.35,  2., -1.229310e+05,  419.36928,  34,  34.,  2096846.4),
       (1723161661500000000, 61594.15,  3., -1.845258e+05,  431.68824,  35,  35.,  2158441.2),
       (1723161662500000000, 61578.15,  4., -2.461194e+05,  444.00696,  36,  36.,  2220034.8),
       (1723161663500000000, 61565.25,  5., -3.076970e+05,  456.32248,  37,  37.,  2281612.4),
       (1723161664500000000, 61563.65,  5., -3.076960e+05,  480.9486 ,  39,  39.,  2404743. ),
       (1723161665500000000, 61555.05,  6., -3.692592e+05,  493.26124,  40,  40.,  2466306.2),
       (1723161666500000000, 61530.85,  7., -4.308138e+05,  505.57216,  41,  41.,  2527860.8),
       (1723161667500000000, 61522.25,  8., -4.923442e+05,  517.87824,  42,  42.,  2589391.2),
       (1723161668500000000, 61543.  ,  7., -4.308214e+05,  530.1828 ,  43,  43.,  2650914. ),
       (1723161669500000000, 61528.05,  7., -4.308214e+05,  530.1828 ,  43,  43.,  2650914. ),
       (1723161670500000000, 61539.85,  8., -4.923490e+05,  542.48832,  44,  44.,  2712441.6),
       (1723161671500000000, 61524.15,  9., -5.538884e+05,  554.7962 ,  45,  45.,  2773981. ),
       (1723161672500000000, 61524.25,  9., -5.538884e+05,  554.7962 ,  45,  45.,  2773981. ),
       (1723161673500000000, 61535.95,  8., -4.923636e+05,  567.10116,  46,  46.,  2835505.8),
       (1723161674500000000, 61531.45,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161675500000000, 61538.85,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161676500000000, 61536.95,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161677500000000, 61538.85,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161678500000000, 61534.75,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161679500000000, 61538.85,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161680500000000, 61538.05,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161681500000000, 61549.25,  9., -5.538990e+05,  579.40824,  47,  47.,  2897041.2),
       (1723161682500000000, 61552.45,  8., -4.923492e+05,  591.7182 ,  48,  48.,  2958591. ),
       (1723161683500000000, 61552.45,  8., -4.923492e+05,  591.7182 ,  48,  48.,  2958591. ),
       (1723161684500000000, 61552.45,  8., -4.923492e+05,  591.7182 ,  48,  48.,  2958591. ),
       (1723161685500000000, 61565.95,  7., -4.307963e+05,  604.02878,  49,  49.,  3020143.9),
       (1723161686500000000, 61574.45,  6., -3.692299e+05,  616.34206,  50,  50.,  3081710.3),
       (1723161687500000000, 61587.55,  6., -3.692299e+05,  616.34206,  50,  50.,  3081710.3),
       (1723161688500000000, 61592.95,  5., -3.076419e+05,  628.65966,  51,  51.,  3143298.3),
       (1723161689500000000, 61592.95,  5., -3.076419e+05,  628.65966,  51,  51.,  3143298.3),
       (1723161690500000000, 61594.15,  5., -3.076419e+05,  628.65966,  51,  51.,  3143298.3),
       (1723161691500000000, 61598.95,  4., -2.460473e+05,  640.97858,  52,  52.,  3204892.9),
       (1723161692500000000, 61593.05,  3., -1.844479e+05,  653.29846,  53,  53.,  3266492.3),
       (1723161693500000000, 61582.55,  3., -1.844479e+05,  653.29846,  53,  53.,  3266492.3),
       (1723161694500000000, 61582.55,  4., -2.460299e+05,  665.61486,  54,  54.,  3328074.3),
       (1723161695500000000, 61582.55,  4., -2.460299e+05,  665.61486,  54,  54.,  3328074.3),
       (1723161696500000000, 61587.15,  4., -2.460299e+05,  665.61486,  54,  54.,  3328074.3),
       (1723161697500000000, 61587.15,  4., -2.460299e+05,  665.61486,  54,  54.,  3328074.3),
       (1723161698500000000, 61588.75,  4., -2.460299e+05,  665.61486,  54,  54.,  3328074.3),
       (1723161699500000000, 61586.75,  4., -2.460289e+05,  690.25034,  56,  56.,  3451251.7),
       (1723161700500000000, 61582.05,  5., -3.076151e+05,  702.56758,  57,  57.,  3512837.9),
       (1723161701500000000, 61572.05,  6., -3.691967e+05,  714.8839 ,  58,  58.,  3574419.5),
       (1723161702500000000, 61587.45,  5., -3.076241e+05,  727.19842,  59,  59.,  3635992.1),
       (1723161703500000000, 61577.95,  5., -3.076241e+05,  727.19842,  59,  59.,  3635992.1),
       (1723161704500000000, 61582.05,  5., -3.076241e+05,  727.19842,  59,  59.,  3635992.1),
       (1723161705500000000, 61572.05,  5., -3.076189e+05,  751.83042,  61,  61.,  3759152.1),
       (1723161706500000000, 61574.05,  4., -2.460463e+05,  764.14494,  62,  62.,  3820724.7),
       (1723161707500000000, 61574.05,  4., -2.460463e+05,  764.14494,  62,  62.,  3820724.7),
       (1723161708500000000, 61576.05,  3., -1.844717e+05,  776.45986,  63,  63.,  3882299.3),
       (1723161709500000000, 61577.55,  2., -1.228951e+05,  788.77518,  64,  64.,  3943875.9),
       (1723161710500000000, 61581.95,  1., -6.131710e+04,  801.09078,  65,  65.,  4005453.9),
       (1723161711500000000, 61565.65,  1., -6.131710e+04,  801.09078,  65,  65.,  4005453.9),
       (1723161712500000000, 61561.15,  2., -1.228823e+05,  813.40382,  66,  66.,  4067019.1),
       (1723161713500000000, 61570.45,  2., -1.228813e+05,  838.02826,  68,  68.,  4190141.3),
       (1723161714500000000, 61572.45,  1., -6.131040e+04,  850.34244,  69,  69.,  4251712.2),
       (1723161715500000000, 61565.65,  1., -6.131040e+04,  850.34244,  69,  69.,  4251712.2),
       (1723161716500000000, 61561.95,  2., -1.228756e+05,  862.65548,  70,  70.,  4313277.4),
       (1723161717500000000, 61557.05,  3., -1.844370e+05,  874.96776,  71,  71.,  4374838.8),
       (1723161718500000000, 61561.95,  3., -1.844370e+05,  874.96776,  71,  71.,  4374838.8),
       (1723161719500000000, 61568.05,  2., -1.228746e+05,  887.28024,  72,  72.,  4436401.2),
       (1723161720500000000, 61576.55,  1., -6.130600e+04,  899.59396,  73,  73.,  4497969.8),
       (1723161721500000000, 61576.55,  1., -6.130600e+04,  899.59396,  73,  73.,  4497969.8),
       (1723161722500000000, 61589.95,  1., -6.130600e+04,  899.59396,  73,  73.,  4497969.8),
       (1723161723500000000, 61593.95,  0.,  2.844000e+02,  911.91204,  74,  74.,  4559560.2),
       (1723161724500000000, 61615.15, -1.,  6.187880e+04,  924.23092,  75,  75.,  4621154.6),
       (1723161725500000000, 61615.15, -1.,  6.187880e+04,  924.23092,  75,  75.,  4621154.6),
       (1723161726500000000, 61615.15, -1.,  6.187880e+04,  924.23092,  75,  75.,  4621154.6),
       (1723161727500000000, 61617.05, -2.,  1.234944e+05,  936.55404,  76,  76.,  4682770.2),
       (1723161728500000000, 61618.15, -3.,  1.851120e+05,  948.87756,  77,  77.,  4744387.8),
       (1723161729500000000, 61612.55, -3.,  1.851120e+05,  948.87756,  77,  77.,  4744387.8),
       (1723161730500000000, 61609.95, -2.,  1.235000e+05,  961.19996,  78,  78.,  4805999.8),
       (1723161731500000000, 61607.95, -1.,  6.189060e+04,  973.52184,  79,  79.,  4867609.2),
       (1723161732500000000, 61608.95, -1.,  6.189060e+04,  973.52184,  79,  79.,  4867609.2),
       (1723161733500000000, 61606.05, -1.,  6.189060e+04,  973.52184,  79,  79.,  4867609.2),
       (1723161734500000000, 61608.45, -1.,  6.189060e+04,  973.52184,  79,  79.,  4867609.2),
       (1723161735500000000, 61615.95, -2.,  1.234995e+05,  985.84362,  80,  80.,  4929218.1),
       (1723161736500000000, 61618.15, -3.,  1.851159e+05,  998.1669 ,  81,  81.,  4990834.5),
       (1723161737500000000, 61605.55, -3.,  1.851159e+05,  998.1669 ,  81,  81.,  4990834.5),
       (1723161738500000000, 61613.85, -3.,  1.851159e+05,  998.1669 ,  81,  81.,  4990834.5),
       (1723161739500000000, 61619.95, -4.,  2.467303e+05, 1010.48978,  82,  82.,  5052448.9),
       (1723161740500000000, 61636.65, -4.,  2.467303e+05, 1010.48978,  82,  82.,  5052448.9),
       (1723161741500000000, 61649.75, -5.,  3.083675e+05, 1022.81722,  83,  83.,  5114086.1),
       (1723161742500000000, 61653.45, -6.,  3.700177e+05, 1035.14726,  84,  84.,  5175736.3),
       (1723161743500000000, 61668.55, -7.,  4.316716e+05, 1047.47804,  85,  85.,  5237390.2),
       (1723161744500000000, 61668.55, -7.,  4.316716e+05, 1047.47804,  85,  85.,  5237390.2),
       (1723161745500000000, 61673.45, -6.,  3.700036e+05, 1059.81164,  86,  86.,  5299058.2),
       (1723161746500000000, 61675.55, -7.,  4.316775e+05, 1072.14642,  87,  87.,  5360732.1),
       (1723161747500000000, 61671.35, -8.,  4.933535e+05, 1084.48162,  88,  88.,  5422408.1),
       (1723161748500000000, 61656.75, -7.,  4.316827e+05, 1096.81578,  89,  89.,  5484078.9),
       (1723161749500000000, 61660.05, -7.,  4.316827e+05, 1096.81578,  89,  89.,  5484078.9),
       (1723161750500000000, 61662.05, -8.,  4.933433e+05, 1109.1479 ,  90,  90.,  5545739.5),
       (1723161751500000000, 61652.05, -7.,  4.316817e+05, 1121.48022,  91,  91.,  5607401.1),
       (1723161752500000000, 61673.45, -7.,  4.316817e+05, 1121.48022,  91,  91.,  5607401.1),
       (1723161753500000000, 61680.65, -8.,  4.933556e+05, 1133.815  ,  92,  92.,  5669075. ),
       (1723161754500000000, 61672.45, -7.,  4.316754e+05, 1146.15104,  93,  93.,  5730755.2),
       (1723161755500000000, 61659.95, -6.,  3.700035e+05, 1158.48542,  94,  94.,  5792427.1),
       (1723161756500000000, 61661.25, -7.,  4.316639e+05, 1170.8175 ,  95,  95.,  5854087.5),
       (1723161757500000000, 61654.25, -7.,  4.316639e+05, 1170.8175 ,  95,  95.,  5854087.5),
       (1723161758500000000, 61650.05, -6.,  3.700101e+05, 1183.14826,  96,  96.,  5915741.3),
       (1723161759500000000, 61650.05, -6.,  3.700101e+05, 1183.14826,  96,  96.,  5915741.3),
       (1723161760500000000, 61654.25, -6.,  3.700101e+05, 1183.14826,  96,  96.,  5915741.3),
       (1723161761500000000, 61652.65, -5.,  3.083563e+05, 1195.47902,  97,  97.,  5977395.1),
       (1723161762500000000, 61663.95, -5.,  3.083563e+05, 1195.47902,  97,  97.,  5977395.1),
       (1723161763500000000, 61656.05, -5.,  3.083563e+05, 1195.47902,  97,  97.,  5977395.1),
       (1723161764500000000, 61656.05, -6.,  3.700129e+05, 1207.81034,  98,  98.,  6039051.7),
       (1723161765500000000, 61626.35, -6.,  3.700129e+05, 1207.81034,  98,  98.,  6039051.7),
       (1723161766500000000, 61629.85, -6.,  3.700129e+05, 1207.81034,  98,  98.,  6039051.7),
       (1723161767500000000, 61629.85, -6.,  3.700129e+05, 1207.81034,  98,  98.,  6039051.7),
       (1723161768500000000, 61633.05, -6.,  3.700129e+05, 1207.81034,  98,  98.,  6039051.7),
       (1723161769500000000, 61645.45, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161770500000000, 61645.45, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161771500000000, 61649.75, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161772500000000, 61640.85, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161773500000000, 61642.05, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161774500000000, 61629.85, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161775500000000, 61629.75, -7.,  4.316465e+05, 1220.13706,  99,  99.,  6100685.3),
       (1723161776500000000, 61635.25, -8.,  4.932767e+05, 1232.4631 , 100, 100.,  6162315.5),
       (1723161777500000000, 61618.75, -7.,  4.316419e+05, 1244.79006, 101, 101.,  6223950.3),
       (1723161778500000000, 61615.75, -6.,  3.700237e+05, 1257.1137 , 102, 102.,  6285568.5),
       (1723161779500000000, 61602.7 , -5.,  3.084085e+05, 1269.43674, 103, 103.,  6347183.7),
       (1723161780500000000, 61609.75, -4.,  2.468063e+05, 1281.75718, 104, 104.,  6408785.9),
       (1723161781500000000, 61629.65, -5.,  3.084165e+05, 1294.07922, 105, 105.,  6470396.1),
       (1723161782500000000, 61634.15, -6.,  3.700467e+05, 1306.40526, 106, 106.,  6532026.3),
       (1723161783500000000, 61631.95, -5.,  3.084131e+05, 1318.73198, 107, 107.,  6593659.9),
       (1723161784500000000, 61625.55, -4.,  2.467817e+05, 1331.05826, 108, 108.,  6655291.3),
       (1723161785500000000, 61617.05, -3.,  1.851567e+05, 1343.38326, 109, 109.,  6716916.3),
       (1723161786500000000, 61620.05, -2.,  1.235401e+05, 1355.70658, 110, 110.,  6778532.9),
       (1723161787500000000, 61620.05, -2.,  1.235401e+05, 1355.70658, 110, 110.,  6778532.9),
       (1723161788500000000, 61620.05, -2.,  1.235401e+05, 1355.70658, 110, 110.,  6778532.9),
       (1723161789500000000, 61617.05, -1.,  6.192050e+04, 1368.0305 , 111, 111.,  6840152.5),
       (1723161790500000000, 61616.15,  0.,  3.039000e+02, 1380.35382, 112, 112.,  6901769.1),
       (1723161791500000000, 61616.15,  0.,  3.039000e+02, 1380.35382, 112, 112.,  6901769.1),
       (1723161792500000000, 61618.05,  0.,  3.039000e+02, 1380.35382, 112, 112.,  6901769.1),
       (1723161793500000000, 61642.05, -1.,  6.192250e+04, 1392.67754, 113, 113.,  6963387.7),
       (1723161794500000000, 61649.95, -2.,  1.235651e+05, 1405.00606, 114, 114.,  7025030.3),
       (1723161795500000000, 61666.45, -3.,  1.852155e+05, 1417.33614, 115, 115.,  7086680.7),
       (1723161796500000000, 61658.05, -3.,  1.852155e+05, 1417.33614, 115, 115.,  7086680.7),
       (1723161797500000000, 61648.45, -2.,  1.235579e+05, 1429.66766, 116, 116.,  7148338.3),
       (1723161798500000000, 61642.05, -2.,  1.235589e+05, 1454.32702, 118, 118.,  7271635.1),
       (1723161799500000000, 61638.85, -1.,  6.191730e+04, 1466.65534, 119, 119.,  7333276.7),
       (1723161800500000000, 61631.95,  0.,  2.789000e+02, 1478.98302, 120, 120.,  7394915.1),
       (1723161801500000000, 61623.05,  1., -6.135250e+04, 1491.3093 , 121, 121.,  7456546.5),
       (1723161802500000000, 61626.65,  1., -6.135250e+04, 1491.3093 , 121, 121.,  7456546.5),
       (1723161803500000000, 61625.05,  1., -6.135250e+04, 1491.3093 , 121, 121.,  7456546.5),
       (1723161804500000000, 61612.05,  2., -1.229771e+05, 1503.63422, 122, 122.,  7518171.1),
       (1723161805500000000, 61618.05,  1., -6.136450e+04, 1515.95674, 123, 123.,  7579783.7),
       (1723161806500000000, 61616.15,  1., -6.136450e+04, 1515.95674, 123, 123.,  7579783.7),
       (1723161807500000000, 61616.15,  1., -6.136450e+04, 1515.95674, 123, 123.,  7579783.7),
       (1723161808500000000, 61602.45,  1., -6.136450e+04, 1515.95674, 123, 123.,  7579783.7),
       (1723161809500000000, 61592.05,  2., -1.229664e+05, 1528.27712, 124, 124.,  7641385.6),
       (1723161810500000000, 61580.25,  3., -1.845580e+05, 1540.59544, 125, 125.,  7702977.2),
       (1723161811500000000, 61580.25,  3., -1.845580e+05, 1540.59544, 125, 125.,  7702977.2),
       (1723161812500000000, 61586.25,  2., -1.229772e+05, 1552.9116 , 126, 126.,  7764558. ),
       (1723161813500000000, 61594.45,  1., -6.139040e+04, 1565.22896, 127, 127.,  7826144.8),
       (1723161814500000000, 61606.85,  0.,  2.045000e+02, 1577.54794, 128, 128.,  7887739.7),
       (1723161815500000000, 61630.35, -1.,  6.181190e+04, 1589.86942, 129, 129.,  7949347.1),
       (1723161816500000000, 61638.05, -2.,  1.234427e+05, 1602.19558, 130, 130.,  8010977.9),
       (1723161817500000000, 61626.25, -2.,  1.234427e+05, 1602.19558, 130, 130.,  8010977.9),
       (1723161818500000000, 61626.25, -2.,  1.234427e+05, 1602.19558, 130, 130.,  8010977.9),
       (1723161819500000000, 61613.65, -2.,  1.234427e+05, 1602.19558, 130, 130.,  8010977.9),
       (1723161820500000000, 61608.15, -1.,  6.182950e+04, 1614.51822, 131, 131.,  8072591.1),
       (1723161821500000000, 61624.65, -2.,  1.234381e+05, 1626.83994, 132, 132.,  8134199.7),
       (1723161822500000000, 61624.65, -2.,  1.234381e+05, 1626.83994, 132, 132.,  8134199.7),
       (1723161823500000000, 61624.65, -2.,  1.234381e+05, 1626.83994, 132, 132.,  8134199.7),
       (1723161824500000000, 61624.65, -2.,  1.234381e+05, 1626.83994, 132, 132.,  8134199.7),
       (1723161825500000000, 61622.55, -1.,  6.181390e+04, 1639.16478, 133, 133.,  8195823.9),
       (1723161826500000000, 61622.55, -1.,  6.181390e+04, 1639.16478, 133, 133.,  8195823.9),
       (1723161827500000000, 61621.65, -1.,  6.181390e+04, 1639.16478, 133, 133.,  8195823.9),
       (1723161828500000000, 61615.95,  0.,  1.927000e+02, 1651.48902, 134, 134.,  8257445.1),
       (1723161829500000000, 61621.55,  1., -6.142270e+04, 1663.8121 , 135, 135.,  8319060.5),
       (1723161830500000000, 61621.55,  1., -6.142270e+04, 1663.8121 , 135, 135.,  8319060.5),
       (1723161831500000000, 61614.05,  1., -6.142270e+04, 1663.8121 , 135, 135.,  8319060.5),
       (1723161832500000000, 61611.55,  2., -1.230363e+05, 1676.13482, 136, 136.,  8380674.1),
       (1723161833500000000, 61620.05,  2., -1.230363e+05, 1676.13482, 136, 136.,  8380674.1),
       (1723161834500000000, 61622.55,  1., -6.141570e+04, 1688.45894, 137, 137.,  8442294.7),
       (1723161835500000000, 61621.55,  1., -6.141470e+04, 1713.10794, 139, 139.,  8565539.7),
       (1723161836500000000, 61630.35,  0.,  2.073000e+02, 1725.43234, 140, 140.,  8627161.7),
       (1723161837500000000, 61613.75, -1.,  6.183810e+04, 1737.7585 , 141, 141.,  8688792.5),
       (1723161838500000000, 61613.75, -1.,  6.183810e+04, 1737.7585 , 141, 141.,  8688792.5),
       (1723161839500000000, 61605.05, -1.,  6.183810e+04, 1737.7585 , 141, 141.,  8688792.5),
       (1723161840500000000, 61616.05, -2.,  1.234437e+05, 1750.07962, 142, 142.,  8750398.1),
       (1723161841500000000, 61621.55, -3.,  1.850603e+05, 1762.40294, 143, 143.,  8812014.7),
       (1723161842500000000, 61633.95, -4.,  2.466823e+05, 1774.72734, 144, 144.,  8873636.7),
       (1723161843500000000, 61638.05, -5.,  3.083167e+05, 1787.05422, 145, 145.,  8935271.1),
       (1723161844500000000, 61634.95, -4.,  2.466791e+05, 1799.38174, 146, 146.,  8996908.7),
       (1723161845500000000, 61634.95, -4.,  2.466791e+05, 1799.38174, 146, 146.,  8996908.7),
       (1723161846500000000, 61638.05, -5.,  3.083145e+05, 1811.70882, 147, 147.,  9058544.1),
       (1723161847500000000, 61634.95, -5.,  3.083155e+05, 1836.36406, 149, 149.,  9181820.3),
       (1723161848500000000, 61626.05, -4.,  2.466811e+05, 1848.69094, 150, 150.,  9243454.7),
       (1723161849500000000, 61629.95, -4.,  2.466811e+05, 1848.69094, 150, 150.,  9243454.7),
       (1723161850500000000, 61629.95, -4.,  2.466811e+05, 1848.69094, 150, 150.,  9243454.7),
       (1723161851500000000, 61632.25, -4.,  2.466811e+05, 1848.69094, 150, 150.,  9243454.7),
       (1723161852500000000, 61635.95, -5.,  3.083139e+05, 1861.0175 , 151, 151.,  9305087.5),
       (1723161853500000000, 61635.95, -5.,  3.083139e+05, 1861.0175 , 151, 151.,  9305087.5),
       (1723161854500000000, 61638.05, -5.,  3.083139e+05, 1861.0175 , 151, 151.,  9305087.5),
       (1723161855500000000, 61636.25, -4.,  2.466763e+05, 1873.34502, 152, 152.,  9366725.1),
       (1723161856500000000, 61638.05, -4.,  2.466763e+05, 1873.34502, 152, 152.,  9366725.1),
       (1723161857500000000, 61636.05, -5.,  3.083149e+05, 1885.67274, 153, 153.,  9428363.7),
       (1723161858500000000, 61641.45, -6.,  3.699515e+05, 1898.00006, 154, 154.,  9490000.3),
       (1723161859500000000, 61641.45, -6.,  3.699515e+05, 1898.00006, 154, 154.,  9490000.3),
       (1723161860500000000, 61643.25, -6.,  3.699515e+05, 1898.00006, 154, 154.,  9490000.3),
       (1723161861500000000, 61657.25, -7.,  4.315953e+05, 1910.32882, 155, 155.,  9551644.1),
       (1723161862500000000, 61671.45, -8.,  4.932531e+05, 1922.66038, 156, 156.,  9613301.9),
       (1723161863500000000, 61668.05, -8.,  4.932531e+05, 1922.66038, 156, 156.,  9613301.9),
       (1723161864500000000, 61669.15, -8.,  4.932531e+05, 1922.66038, 156, 156.,  9613301.9),
       (1723161865500000000, 61666.75, -8.,  4.932531e+05, 1922.66038, 156, 156.,  9613301.9),
       (1723161866500000000, 61665.05, -7.,  4.315869e+05, 1934.99362, 157, 157.,  9674968.1),
       (1723161867500000000, 61657.15, -6.,  3.699223e+05, 1947.32654, 158, 158.,  9736632.7),
       (1723161868500000000, 61657.15, -6.,  3.699223e+05, 1947.32654, 158, 158.,  9736632.7),
       (1723161869500000000, 61657.15, -6.,  3.699223e+05, 1947.32654, 158, 158.,  9736632.7),
       (1723161870500000000, 61657.15, -6.,  3.699223e+05, 1947.32654, 158, 158.,  9736632.7),
       (1723161871500000000, 61666.75, -7.,  4.315799e+05, 1959.65806, 159, 159.,  9798290.3),
       (1723161872500000000, 61651.55, -6.,  3.699137e+05, 1971.9913 , 160, 160.,  9859956.5),
       (1723161873500000000, 61638.05, -5.,  3.082627e+05, 1984.3215 , 161, 161.,  9921607.5),
       (1723161874500000000, 61634.35, -4.,  2.466251e+05, 1996.64902, 162, 162.,  9983245.1),
       (1723161875500000000, 61638.85, -4.,  2.466251e+05, 1996.64902, 162, 162.,  9983245.1),
       (1723161876500000000, 61638.15, -5.,  3.082645e+05, 2008.9769 , 163, 163., 10044884.5),
       (1723161877500000000, 61621.65, -4.,  2.466269e+05, 2021.30442, 164, 164., 10106522.1),
       (1723161878500000000, 61611.65, -3.,  1.850057e+05, 2033.62866, 165, 165., 10168143.3),
       (1723161879500000000, 61614.95, -4.,  2.466179e+05, 2045.9511 , 166, 166., 10229755.5),
       (1723161880500000000, 61614.15, -4.,  2.466179e+05, 2045.9511 , 166, 166., 10229755.5),
       (1723161881500000000, 61614.15, -4.,  2.466179e+05, 2045.9511 , 166, 166., 10229755.5),
       (1723161882500000000, 61614.15, -4.,  2.466179e+05, 2045.9511 , 166, 166., 10229755.5),
       (1723161883500000000, 61616.15, -4.,  2.466179e+05, 2045.9511 , 166, 166., 10229755.5),
       (1723161884500000000, 61623.95, -5.,  3.082345e+05, 2058.27442, 167, 167., 10291372.1),
       (1723161885500000000, 61627.95, -6.,  3.698589e+05, 2070.5993 , 168, 168., 10352996.5),
       (1723161886500000000, 61621.45, -6.,  3.698589e+05, 2070.5993 , 168, 168., 10352996.5),
       (1723161887500000000, 61620.45, -5.,  3.082380e+05, 2082.92348, 169, 169., 10414617.4),
       (1723161888500000000, 61617.55, -4.,  2.466181e+05, 2095.24746, 170, 170., 10476237.3),
       (1723161889500000000, 61609.45, -3.,  1.850011e+05, 2107.57086, 171, 171., 10537854.3),
       (1723161890500000000, 61609.45, -3.,  1.850011e+05, 2107.57086, 171, 171., 10537854.3),
       (1723161891500000000, 61605.95, -3.,  1.850011e+05, 2107.57086, 171, 171., 10537854.3),
       (1723161892500000000, 61605.95, -3.,  1.850011e+05, 2107.57086, 171, 171., 10537854.3),
       (1723161893500000000, 61596.55, -3.,  1.850011e+05, 2107.57086, 171, 171., 10537854.3),
       (1723161894500000000, 61595.65, -2.,  1.234051e+05, 2119.89006, 172, 172., 10599450.3),
       (1723161895500000000, 61580.75, -1.,  6.180990e+04, 2132.2091 , 173, 173., 10661045.5),
       (1723161896500000000, 61575.05,  0.,  2.297000e+02, 2144.52514, 174, 174., 10722625.7),
       (1723161897500000000, 61585.05,  0.,  2.297000e+02, 2144.52514, 174, 174., 10722625.7),
       (1723161898500000000, 61578.25,  0.,  2.297000e+02, 2144.52514, 174, 174., 10722625.7),
       (1723161899500000000, 61578.25,  0.,  2.297000e+02, 2144.52514, 174, 174., 10722625.7),
       (1723161900500000000, 61583.95, -1.,  6.180850e+04, 2156.8409 , 175, 175., 10784204.5),
       (1723161901500000000, 61583.95, -1.,  6.180850e+04, 2156.8409 , 175, 175., 10784204.5),
       (1723161902500000000, 61583.95, -1.,  6.180850e+04, 2156.8409 , 175, 175., 10784204.5),
       (1723161903500000000, 61585.05, -2.,  1.233929e+05, 2169.15778, 176, 176., 10845788.9)],
      dtype={'names': ['timestamp', 'price', 'position', 'balance', 'fee', 'num_trades', 'trading_volume', 'trading_value'], 'formats': ['<i8', '<f8', '<f8', '<f8', '<f8', '<i8', '<f8', '<f8'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64, 'aligned': True})
Additionally, the to_npz method saves all records into an npz file, with the asset number as the key for the data.

recorder.to_npz('example_record.npz')
HftBacktest also provides a performance reporting tool based on the records. Please see the details here.

from hftbacktest.stats import LinearAssetRecord

# Constructs the LinearAssetRecord from the recorded data.
record = LinearAssetRecord(recorder.get(0))

# Generates the statistics.
# You can generate monthly and daily statistics, as well as custom metrics.
stats = record.stats()

# Prints the summary.
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTradingValue	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2024-08-09 00:00:00	2024-08-09 00:05:00	-624.497686	-664.628958	-1846.54472	1902.18778	50688.0	3.1236e9	-0.970748	-0.00017	553849.65
stats.plot()
../_images/tutorials_Getting_Started_53_0.png
Bokeh using Holoviews is also supported.

import holoviews as hv
hv.extension('bokeh')

stats.plot(backend='holoviews')

© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest 

hftbacktest
Search docs
Tutorials

Data Preparation
Getting started from Binance Futures’ raw feed data
Creating a market depth snapshot
Getting started from Tardis.dev data
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Power AI apps with data from any AWS, Google Cloud, or Azure region on MongoDB Atlas. Try free!
Ads by EthicalAds
Close Ad
 Data PreparationView page source
Data Preparation
To fully utilize the power of HftBacktest, it requires to input Tick-by-Tick full order book and trade feed data. Unfortunately, free Tick-by-Tick full order book and trade feed data for HFT is not available unlike daily bar data provided by platforms like Yahoo Finance. However, in the case of cryptocurrency, you can collect the full raw feed yourself.

Getting started from Binance Futures’ raw feed data
You can collect Binance Futures feed yourself using Data Collector.

import gzip

with gzip.open('usdm/btcusdt_20240808.gz', 'r') as f:
    for i in range(5):
        line = f.readline()
        print(line)
b'1723161255030314667 {"stream":"btcusdt@depth@0ms","data":{"e":"depthUpdate","E":1723161256299,"T":1723161256298,"s":"BTCUSDT","U":5123107832006,"u":5123107837557,"pu":5123107831937,"b":[["58710.20","0.014"],["61496.50","0.010"],["61510.90","0.000"],["61641.50","1.211"],["61652.80","0.195"],["61653.30","0.072"],["61653.70","0.067"],["61657.90","0.067"],["61668.50","0.086"],["61670.60","0.161"],["61672.50","0.821"],["61673.60","0.048"],["61675.60","0.050"],["61684.50","0.765"],["61686.20","0.008"],["61701.80","0.331"],["61703.10","0.238"],["61715.90","0.308"],["61721.60","0.235"],["61724.10","0.002"],["61737.00","0.015"],["61739.00","0.000"],["61740.10","0.008"],["61740.50","12.111"],["61756.90","0.550"],["61758.70","0.003"],["61763.20","0.014"],["61764.10","0.168"],["61764.30","0.000"],["61765.50","0.000"],["61767.40","0.004"],["61768.20","0.120"],["61768.60","0.020"],["61768.90","0.099"],["61770.80","0.049"],["61771.10","0.612"],["61771.70","0.010"],["61773.50","0.035"],["61773.80","0.025"],["61774.00","0.112"],["61775.60","0.010"],["61776.00","0.084"],["61778.30","0.000"],["61778.60","0.408"],["61779.30","0.020"],["61779.60","0.220"],["61783.80","0.002"],["61784.90","0.102"],["61785.00","0.000"],["61788.10","0.140"],["61789.50","0.000"],["61798.70","0.153"],["61800.20","2.507"]],"a":[["61800.30","3.330"],["61804.60","0.057"],["61810.00","0.285"],["61812.00","0.732"],["61814.90","0.000"],["61817.20","0.000"],["61818.70","0.040"],["61824.00","0.860"],["61829.10","0.185"],["61831.30","0.008"],["61831.40","0.501"],["61839.00","0.002"],["61840.00","0.192"],["61856.30","0.003"],["61857.10","0.027"],["61857.40","0.000"],["61858.80","0.005"],["61858.90","0.032"],["61859.60","0.034"],["61874.80","0.006"],["61893.40","0.335"],["61911.90","0.014"],["61925.90","0.000"],["61930.50","0.015"],["61945.10","0.000"],["61953.70","0.000"],["62144.00","0.006"],["63113.70","0.000"],["65880.70","15.918"]]}}\n'
b'1723161255088169167 {"stream":"btcusdt@bookTicker","data":{"e":"bookTicker","u":5123107839020,"s":"BTCUSDT","b":"61800.20","B":"2.507","a":"61800.30","A":"2.510","T":1723161256313,"E":1723161256313}}\n'
b'1723161255088176367 {"stream":"btcusdt@trade","data":{"e":"trade","E":1723161256322,"T":1723161256322,"s":"BTCUSDT","t":5266583935,"p":"61800.30","q":"0.006","X":"MARKET","m":false}}\n'
b'1723161255088181667 {"stream":"btcusdt@bookTicker","data":{"e":"bookTicker","u":5123107840008,"s":"BTCUSDT","b":"61800.20","B":"2.507","a":"61800.30","A":"2.504","T":1723161256322,"E":1723161256322}}\n'
b'1723161255088182467 {"stream":"btcusdt@bookTicker","data":{"e":"bookTicker","u":5123107840016,"s":"BTCUSDT","b":"61800.20","B":"2.507","a":"61800.30","A":"2.522","T":1723161256322,"E":1723161256322}}\n'
The first token of the line is timestamp received by local.

Note: The timestamp is in nanoseconds.

The data needs to be converted to normalized data that can be fed into HftBacktest.
convert method also attempts to correct timestamps by reordering the rows.
import numpy as np

from hftbacktest.data.utils import binancefutures

data = binancefutures.convert(
    'usdm/btcusdt_20240808.gz',
    combined_stream=True
)
Correcting the latency
local_timestamp is ahead of exch_timestamp by 1272156851
Correcting the event order
Normalized data as follows. You can find more details on Data.

import polars as pl

pl.DataFrame(data)
shape: (491_973, 8)
ev	exch_ts	local_ts	px	qty	order_id	ival	fval
u64	i64	i64	f64	f64	u64	i64	f64
3758096385	1723161256298000000	1723161256302471518	58710.2	0.014	0	0	0.0
3758096385	1723161256298000000	1723161256302471518	61496.5	0.01	0	0	0.0
3758096385	1723161256298000000	1723161256302471518	61510.9	0.0	0	0	0.0
3758096385	1723161256298000000	1723161256302471518	61641.5	1.211	0	0	0.0
3758096385	1723161256298000000	1723161256302471518	61652.8	0.195	0	0	0.0
…	…	…	…	…	…	…	…
3489660929	1723161600030000000	1723161600043617932	62292.9	0.0	0	0	0.0
3758096385	1723161600319000000	1723161600370793433	5000.0	2.321	0	0	0.0
3489660929	1723161600709000000	1723161600760777134	61659.8	0.981	0	0	0.0
3758096385	1723161601054000000	1723161601105649435	61631.7	0.283	0	0	0.0
3758096385	1723161601054000000	1723161601105649435	61632.6	0.0	0	0	0.0
You can save the data directly to a file by providing output_filename.

_ = binancefutures.convert(
    'usdm/btcusdt_20240808.gz',
    output_filename='usdm/btcusdt_20240808.npz',
    combined_stream=True
)
Correcting the latency
local_timestamp is ahead of exch_timestamp by 1272156851
Correcting the event order
Saving to usdm/btcusdt_20240808.npz
Creating a market depth snapshot
As Binance Futures exchange runs 24/7, you need the initial snapshot to get the complete(almost) market depth.
Data Collector fetches the snapshot only when it makes the connection, so you need build the initial snapshot from the start of the collected feed data.
from hftbacktest.data.utils.snapshot import create_last_snapshot

# Builds 20240808 End of Day snapshot. It will be used for the initial snapshot for 20240809.
data = create_last_snapshot(
    ['usdm/btcusdt_20240808.npz'],
    tick_size=0.1,
    lot_size=0.001
)
Bid levels are shown before ask levels in the snapshot, and levels are sorted from the best price to the farthest price.

pl.DataFrame(data)
shape: (9_597, 8)
ev	exch_ts	local_ts	px	qty	order_id	ival	fval
u64	i64	i64	f64	f64	u64	i64	f64
3758096388	0	0	61659.7	1.486	0	0	0.0
3758096388	0	0	61659.0	0.002	0	0	0.0
3758096388	0	0	61658.1	0.033	0	0	0.0
3758096388	0	0	61658.0	6.718	0	0	0.0
3758096388	0	0	61657.9	0.007	0	0	0.0
…	…	…	…	…	…	…	…
3489660932	0	0	77354.3	0.015	0	0	0.0
3489660932	0	0	77905.9	0.003	0	0	0.0
3489660932	0	0	80000.0	10.708	0	0	0.0
3489660932	0	0	104765.0	0.034	0	0	0.0
3489660932	0	0	617050.0	0.003	0	0	0.0
from hftbacktest.data.utils.snapshot import create_last_snapshot

# Builds 20240808 End of Day snapshot. It will be used for the initial snapshot for 20240809.
_ = create_last_snapshot(
    ['usdm/btcusdt_20240808.npz'],
    tick_size=0.1,
    lot_size=0.001,
    output_snapshot_filename='usdm/btcusdt_20240808_eod.npz'
)
# Converts 20240809 data.
_ = binancefutures.convert(
    'usdm/btcusdt_20240809.gz',
    output_filename='usdm/btcusdt_20240809.npz',
    combined_stream=True
)

# Builds 20240809's last snapshot.
# Due to the file size limitation of GitHub, btcusdt_20240809.npz does not contain data for the entire day.
_ = create_last_snapshot(
    ['usdm/btcusdt_20240809.npz'],
    tick_size=0.1,
    lot_size=0.001,
    output_snapshot_filename='usdm/btcusdt_20240809_last.npz',
    initial_snapshot='usdm/btcusdt_20240808_eod.npz',
)
Correcting the latency
local_timestamp is ahead of exch_timestamp by 1273873720
Correcting the event order
Saving to usdm/btcusdt_20240809.npz
# Builds 20240809's last snapshot without the initial snapshot.
_ = create_last_snapshot(
    ['usdm/btcusdt_20240809.npz'],
    tick_size=0.1,
    lot_size=0.001,
    output_snapshot_filename='usdm/btcusdt_20240809_last_wo_ss.npz'
)

# Builds the 20240809's last snapshot from 20240808 without the initial snapshot.
_ = create_last_snapshot(
    [
        'usdm/btcusdt_20240808.npz',
        'usdm/btcusdt_20240809.npz'
    ],
    tick_size=0.1,
    lot_size=0.001,
    output_snapshot_filename='usdm/btcusdt_20240809_last.npz'
)
Getting started from Tardis.dev data
Few vendors offer tick-by-tick full market depth data along with snapshot and trade data, and Tardis.dev is among them.

Note: Some data may have an issue with the exchange timestamp. Ideally, the exchange timestamp should reflect the moment the event occurs at the matching engine. However, some data uses the server’s data sent timestamp instead of the matching engine timestamp.

# https://docs.tardis.dev/historical-data-details/binance-futures

# Downloads sample Binance futures BTCUSDT trades
!wget https://datasets.tardis.dev/v1/binance-futures/trades/2020/02/01/BTCUSDT.csv.gz -O BTCUSDT_trades.csv.gz

# Downloads sample Binance futures BTCUSDT book
!wget https://datasets.tardis.dev/v1/binance-futures/incremental_book_L2/2020/02/01/BTCUSDT.csv.gz -O BTCUSDT_book.csv.gz
--2024-08-09 09:42:51--  https://datasets.tardis.dev/v1/binance-futures/trades/2020/02/01/BTCUSDT.csv.gz
Resolving datasets.tardis.dev (datasets.tardis.dev)... 104.18.6.96, 104.18.7.96, 2606:4700::6812:760, ...
Connecting to datasets.tardis.dev (datasets.tardis.dev)|104.18.6.96|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3090479 (2.9M) [text/csv]
Saving to: ‘BTCUSDT_trades.csv.gz’

BTCUSDT_trades.csv. 100%[===================>]   2.95M  5.66MB/s    in 0.5s

2024-08-09 09:42:52 (5.66 MB/s) - ‘BTCUSDT_trades.csv.gz’ saved [3090479/3090479]

--2024-08-09 09:42:52--  https://datasets.tardis.dev/v1/binance-futures/incremental_book_L2/2020/02/01/BTCUSDT.csv.gz
Resolving datasets.tardis.dev (datasets.tardis.dev)... 104.18.7.96, 104.18.6.96, 2606:4700::6812:760, ...
Connecting to datasets.tardis.dev (datasets.tardis.dev)|104.18.7.96|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 250016849 (238M) [text/csv]
Saving to: ‘BTCUSDT_book.csv.gz’

BTCUSDT_book.csv.gz 100%[===================>] 238.43M  9.93MB/s    in 23s

2024-08-09 09:43:16 (10.3 MB/s) - ‘BTCUSDT_book.csv.gz’ saved [250016849/250016849]

It is recommended to input trade files before depth files. This is because if a depth event occurs due to a trade event, having the trade event before the depth event could provide a more realistic fill during backtesting. However, the sorting process will prioritize events from the first input file when both events have the same timestamp.

from hftbacktest.data.utils import tardis

data = tardis.convert(
    ['BTCUSDT_trades.csv.gz', 'BTCUSDT_book.csv.gz']
)
Reading BTCUSDT_trades.csv.gz
Reading BTCUSDT_book.csv.gz
Correcting the latency
Correcting the event order
pl.DataFrame(data)
shape: (27_532_602, 8)
ev	exch_ts	local_ts	px	qty	order_id	ival	fval
u64	i64	i64	f64	f64	u64	i64	f64
3758096386	1580515202342000000	1580515202497052000	9364.51	1.197	0	0	0.0
3758096386	1580515202342000000	1580515202497346000	9365.67	0.02	0	0	0.0
3758096386	1580515202342000000	1580515202497352000	9365.86	0.01	0	0	0.0
3758096386	1580515202342000000	1580515202497357000	9366.36	0.002	0	0	0.0
3758096386	1580515202342000000	1580515202497363000	9366.36	0.003	0	0	0.0
…	…	…	…	…	…	…	…
3489660929	1580601599812000000	1580601599944404000	9397.79	0.0	0	0	0.0
3758096385	1580601599826000000	1580601599952176000	9354.8	4.07	0	0	0.0
3758096385	1580601599836000000	1580601599962961000	9351.47	3.914	0	0	0.0
3489660929	1580601599836000000	1580601599963461000	9397.78	0.1	0	0	0.0
3758096385	1580601599848000000	1580601599973647000	9348.14	3.98	0	0	0.0
You can save the data directly to a file by providing output_filename. If there are too many rows, you need to increase buffer_size.

_ = tardis.convert(
    ['BTCUSDT_trades.csv.gz', 'BTCUSDT_book.csv.gz'],
    output_filename='btcusdt_20200201.npz',
    buffer_size=200_000_000
)
Reading BTCUSDT_trades.csv.gz
Reading BTCUSDT_book.csv.gz
Correcting the latency
Correcting the event order
Saving to btcusdt_20200201.npz
Tardis.dev artificially inserts the SOD snapshot to the start of the daily file. If you continuously backtest multiple days, you don’t need the snapshot every start of days and it may incur more time to backtest. You can choose to include the Tardis.dev’s SOD snapshot in the converted file using the option.

© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Overview
Guéant–Lehalle–Fernandez-Tapia Market Making Model
Calculating Trading Intensity
Implement a Market Maker using the Model
Adjustment factors
Integrating Grid Trading
Wrapping up
References
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Copilot & Cursor letting you down? The AI Agent that gets your codebase Install Augment Now
Ads by EthicalAds
Close Ad
 Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid TradingView page source
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Overview
Grid trading is straightforward and easy to comprehend, and it excels in high-frequency environments. However, given the intricacies of high-frequency trading, which necessitate comprehensive tick-by-tick simulation with latencies and order fill simulation, optimizing the ideal spread, order interval, and skew can be a challenging task. Furthermore, these values fluctuate over time, especially in response to market conditions, making a fixed setup less than optimal.

To improve grid trading’s adaptability, one solution is to combine it with a well-developed market-making model. Let’s delve into how this can be achieved.

Guéant–Lehalle–Fernandez-Tapia Market Making Model
This model represents an advanced evolution of the well-known Avellaneda-Stoikov model and provides a closed-form approximation of asymptotic behavior for terminal time T. Simply, this model does not specify a terminal time, which makes it suitable for typical stocks, spot assets, or crypto perpetual contracts. By employing this model, it is anticipated that the half spread and skew will be accurately adjusted according to market conditions.

In this analysis, we will focus on equations (4.6) and (4.7) in Optimal market making and explore how they can be applied to real-world scenarios.

The optimal bid quote depth, 
, and ask quote depth, 
, are derived from the fair price as follows:

 
 
 
 
 
 
 
 
 
 
 
 
 

Let’s introduce 
 and 
 and define them by extracting the volatility 𝜎 from the square root:

 
 
 
 
 
 

Now we can rewrite equations (4.6) and (4.7) as follows:

 
 
 

As you can see, this consists of the half spread and skew. 
 represents a market maker’s inventory(position).

 
 

Thus,

 

You can find similarities in what the following two articles describe.
Stochastic Control Theory and High Frequency Trading
How to Market Make Bitcoin Derivatives Lesson 2
Calculating Trading Intensity
To determine the optimal quotes, we need to compute 
 and 
. In order to do that, we need to calibrate 
 and 
 of trading intensity, as well as calculate the market volatility 
.

Trading intensity is defined as:

We will calibrate these values using market data according to the this article. In order to do that, we need to record market order’s arrivals.

Our market maker will react every 100ms, which means they will post or cancel orders at this interval. So, our quotes’ trading intensity will be measured in the same time-step. Ideally, we should also account for our orders’ queue position; however, to simplify the problem, we will not consider the order queue position in this analysis.

from numba import njit
from hftbacktest import BUY_EVENT

import numpy as np

@njit
def measure_trading_intensity_and_volatility(hbt):
    tick_size = hbt.depth(0).tick_size
    arrival_depth = np.full(10_000_000, np.nan, np.float64)
    mid_price_chg = np.full(10_000_000, np.nan, np.float64)

    t = 0
    prev_mid_price_tick = np.nan
    mid_price_tick = np.nan

    # Checks every 100 milliseconds.
    while hbt.elapse(100_000_000) == 0:
        #--------------------------------------------------------
        # Records market order's arrival depth from the mid-price.
        if not np.isnan(mid_price_tick):
            depth = -np.inf
            for last_trade in hbt.last_trades(0):
                trade_price_tick = last_trade.px / tick_size

                if last_trade.ev & BUY_EVENT == BUY_EVENT:
                    depth = np.nanmax([trade_price_tick - mid_price_tick, depth])
                else:
                    depth = np.nanmax([mid_price_tick - trade_price_tick, depth])
            arrival_depth[t] = depth

        hbt.clear_last_trades(0)

        depth = hbt.depth(0)

        best_bid_tick = depth.best_bid_tick
        best_ask_tick = depth.best_ask_tick

        prev_mid_price_tick = mid_price_tick
        mid_price_tick = (best_bid_tick + best_ask_tick) / 2.0

        # Records the mid-price change for volatility calculation.
        mid_price_chg[t] = mid_price_tick - prev_mid_price_tick

        t += 1
        if t >= len(arrival_depth) or t >= len(mid_price_chg):
            raise Exception
    return arrival_depth[:t], mid_price_chg[:t]
Since we’re not considering the order’s queue position when measuring trading intensity, only market trades that cross our quote will be counted as executed.

Note: The trading intensity in out of measure_trading_intensity is incorrectly in half-tick units instead of tick units. Although this fix requires adjusting parameters in all related examples, the example is left unchanged to preserve existing results.

@njit
def measure_trading_intensity(order_arrival_depth, out):
    max_tick = 0
    for depth in order_arrival_depth:
        if not np.isfinite(depth):
            continue

        # Sets the tick index to 0 for the nearest possible best price
        # as the order arrival depth in ticks is measured from the mid-price
        tick = round(depth / .5) - 1

        # In a fast-moving market, buy trades can occur below the mid-price (and vice versa for sell trades)
        # since the mid-price is measured in a previous time-step;
        # however, to simplify the problem, we will exclude those cases.
        if tick < 0 or tick >= len(out):
            continue

        # All of our possible quotes within the order arrival depth,
        # excluding those at the same price, are considered executed.
        out[:tick] += 1

        max_tick = max(max_tick, tick)
    return out[:max_tick]
Run HftBacktest to replay the market and record order arrival depth and price changes.

from hftbacktest import BacktestAsset, ROIVectorMarketDepthBacktest

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20221003.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20221003.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

arrival_depth, mid_price_chg = measure_trading_intensity_and_volatility(hbt)

_ = hbt.close()
Measure trading intensity from the recorded order arrival depth and plot it.

tmp = np.zeros(500, np.float64)

# Measures trading intensity (lambda) for the first 10-minute window.
lambda_ = measure_trading_intensity(arrival_depth[:6_000], tmp)

# Since it is measured for a 10-minute window, divide by 600 to convert it to per second.
lambda_ /= 600

# Creates ticks from the mid-price.
ticks = np.arange(len(lambda_)) + .5
from matplotlib import pyplot as plt

plt.plot(ticks, lambda_)
plt.xlabel('$ \delta $ (ticks from the mid-price)')
plt.ylabel('Count (per second)')
Text(0, 0.5, 'Count (per second)')
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_11_1.png
Calibrate 
 and 
 using linear regression, since by taking the logarithm of both sides of lambda, it becomes 
.

@njit
def linear_regression(x, y):
    sx = np.sum(x)
    sy = np.sum(y)
    sx2 = np.sum(x ** 2)
    sxy = np.sum(x * y)
    w = len(x)
    slope = (w * sxy - sx * sy) / (w * sx2 - sx**2)
    intercept = (sy - slope * sx) / w
    return slope, intercept
y = np.log(lambda_)
k_, logA = linear_regression(ticks, y)
A = np.exp(logA)
k = -k_

print('A={}, k={}'.format(A, k))
A=0.8426573649994981, k=0.016958811558646644
plt.plot(lambda_)
plt.plot(A * np.exp(-k * ticks))
plt.xlabel('$ \delta $ (ticks from the mid-price)')
plt.ylabel('Count (per second)')
plt.legend(['Actual', 'Fitted curve'])
<matplotlib.legend.Legend at 0x7fac86b74760>
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_15_1.png
As you can see, the fitted lambda function is not accurate across the entire range. More specifically, it overestimates the trading intensity for the shallow range near the mid-price and underestimates it for the deep range away from the mid-price.

Since our quotes are likely to be placed in the range close to the mid-price, at least under typical market conditions (excluding high volatility conditions), we will refit the function specifically for the nearest range.

# Refits for the range un to 70 ticks.
x_shallow = ticks[:70]
lambda_shallow = lambda_[:70]

y = np.log(lambda_shallow)
k_, logA = linear_regression(x_shallow, y)
A = np.exp(logA)
k = -k_

print('A={}, k={}'.format(A, k))
A=2.986162360812285, k=0.04235741115084049
plt.plot(lambda_shallow)
plt.plot(A * np.exp(-k * x_shallow))
plt.xlabel('$ \delta $ (ticks from the mid-price)')
plt.ylabel('Count (per second)')
plt.legend(['Actual', 'Fitted curve'])
<matplotlib.legend.Legend at 0x7fac86b77070>
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_18_1.png
Now, we have a more accurate trading intensity function. Let’s see where our quote will be placed.

But before we do that, let’s calculate the volatility first.

# Since we need volatility in ticks per square root of a second and our measurement is every 100ms,
# multiply by the square root of 10.
volatility = np.nanstd(mid_price_chg) * np.sqrt(10)
print(volatility)
10.725509539115974
Compute 
 and 
 according to the equations.

@njit
def compute_coeff(xi, gamma, delta, A, k):
    inv_k = np.divide(1, k)
    c1 = 1 / (xi * delta) * np.log(1 + xi * delta * inv_k)
    c2 = np.sqrt(np.divide(gamma, 2 * A * delta * k) * ((1 + xi * delta * inv_k) ** (k / (xi * delta) + 1)))
    return c1, c2
In the Guéant–Lehalle–Fernandez-Tapia formula, 
 and 
. the value of 
 is arbitrarily chosen.

gamma = 0.05
delta = 1
volatility = 10.69

c1, c2 = compute_coeff(gamma, gamma, delta, A, k)

half_spread_tick = 1 * c1 + 1 / 2 * c2 * volatility
skew = c2 * volatility
print('half_spread_tick={}, skew={}'.format(half_spread_tick, skew))
half_spread_tick=20.47208533844371, skew=9.76326865029227
What does it mean when your quote is positioned 20 ticks away from the mid-price? By analyzing the recorded order arrival depth, you can identify the number of market trades you’ll participate in as a market maker, measured in terms of count instead of volume. Additionally, the skew appears to be quite strong, as accumulating just two positions offsets the entire half spread.

from scipy import stats

# inverse of percentile
pct = stats.percentileofscore(arrival_depth[np.isfinite(arrival_depth)], half_spread_tick)
your_pct = 100 - pct
print('{:.2f}%'.format(your_pct))
1.86%
Approximately 1.86% of market trades per given time-step could execute your quote. Be aware that it’s not the percentage of the traded quantity.

Implement a Market Maker using the Model
Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.005% rebate, the highest market maker rebate available on Binance Futures. See Binance Upgrades USDⓢ-Margined Futures Liquidity Provider Program for more details.

In this example, we will disregard the forecast term and assume that the fair price is equal to the mid price, as we can expect the intrinsic value to remain stable in the short term.

from numba.typed import Dict
from hftbacktest import BUY, SELL, GTX, LIMIT

out_dtype = np.dtype([
    ('half_spread_tick', 'f8'),
    ('skew', 'f8'),
    ('volatility', 'f8'),
    ('A', 'f8'),
    ('k', 'f8')
])

@njit
def glft_market_maker(hbt, recorder):
    tick_size = hbt.depth(0).tick_size
    arrival_depth = np.full(10_000_000, np.nan, np.float64)
    mid_price_chg = np.full(10_000_000, np.nan, np.float64)
    out = np.zeros(10_000_000, out_dtype)

    t = 0
    prev_mid_price_tick = np.nan
    mid_price_tick = np.nan

    tmp = np.zeros(500, np.float64)
    ticks = np.arange(len(tmp)) + 0.5

    A = np.nan
    k = np.nan
    volatility = np.nan
    gamma = 0.05
    delta = 1

    order_qty = 1
    max_position = 20

    # Checks every 100 milliseconds.
    while hbt.elapse(100_000_000) == 0:
        #--------------------------------------------------------
        # Records market order's arrival depth from the mid-price.
        if not np.isnan(mid_price_tick):
            depth = -np.inf
            for last_trade in hbt.last_trades(0):
                trade_price_tick = last_trade.px / tick_size

                if last_trade.ev & BUY_EVENT == BUY_EVENT:
                    depth = np.nanmax([trade_price_tick - mid_price_tick, depth])
                else:
                    depth = np.nanmax([mid_price_tick - trade_price_tick, depth])
            arrival_depth[t] = depth

        hbt.clear_last_trades(0)
        hbt.clear_inactive_orders(0)

        depth = hbt.depth(0)
        position = hbt.position(0)
        orders = hbt.orders(0)

        best_bid_tick = depth.best_bid_tick
        best_ask_tick = depth.best_ask_tick

        prev_mid_price_tick = mid_price_tick
        mid_price_tick = (best_bid_tick + best_ask_tick) / 2.0

        # Records the mid-price change for volatility calculation.
        mid_price_chg[t] = mid_price_tick - prev_mid_price_tick

        #--------------------------------------------------------
        # Calibrates A, k and calculates the market volatility.

        # Updates A, k, and the volatility every 5-sec.
        if t % 50 == 0:
            # Window size is 10-minute.
            if t >= 6_000 - 1:
                # Calibrates A, k
                tmp[:] = 0
                lambda_ = measure_trading_intensity(arrival_depth[t + 1 - 6_000:t + 1], tmp)
                if len(lambda_) > 2:
                    lambda_ = lambda_[:70] / 600
                    x = ticks[:len(lambda_)]
                    y = np.log(lambda_)
                    k_, logA = linear_regression(x, y)
                    A = np.exp(logA)
                    k = -k_

                # Updates the volatility.
                volatility = np.nanstd(mid_price_chg[t + 1 - 6_000:t + 1]) * np.sqrt(10)

        #--------------------------------------------------------
        # Computes bid price and ask price.

        c1, c2 = compute_coeff(gamma, gamma, delta, A, k)

        half_spread_tick = c1 + delta / 2 * c2 * volatility
        skew = c2 * volatility

        reservation_price_tick = mid_price_tick - skew * position

        bid_price_tick = np.minimum(np.round(reservation_price_tick - half_spread_tick), best_bid_tick)
        ask_price_tick = np.maximum(np.round(reservation_price_tick + half_spread_tick), best_ask_tick)

        bid_price = bid_price_tick * tick_size
        ask_price = ask_price_tick * tick_size

        #--------------------------------------------------------
        # Updates quotes.

        # Cancel orders if they differ from the updated bid and ask prices.
        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.price != bid_price)
                    or (order.side == SELL and order.price != ask_price)
                ):
                    hbt.cancel(0, order.order_id, False)

        # If the current position is within the maximum position,
        # submit the new order only if no order exists at the same price.
        if position < max_position and np.isfinite(bid_price):
            bid_price_as_order_id = round(bid_price / tick_size)
            if bid_price_as_order_id not in orders:
                hbt.submit_buy_order(0, bid_price_as_order_id, bid_price, order_qty, GTX, LIMIT, False)
        if position > -max_position and np.isfinite(ask_price):
            ask_price_as_order_id = round(ask_price / tick_size)
            if ask_price_as_order_id not in orders:
                hbt.submit_sell_order(0, ask_price_as_order_id, ask_price, order_qty, GTX, LIMIT, False)

        #--------------------------------------------------------
        # Records variables and stats for analysis.

        out[t].half_spread_tick = half_spread_tick
        out[t].skew = skew
        out[t].volatility = volatility
        out[t].A = A
        out[t].k = k

        t += 1

        if t >= len(arrival_depth) or t >= len(mid_price_chg) or t >= len(out):
            raise Exception

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return out[:t]
from hftbacktest import Recorder
from hftbacktest.stats import LinearAssetRecord

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20221003.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20221003.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

out = glft_market_maker(hbt, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=30_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-03 23:59:50	-246.379582	-264.130529	-0.020574	0.020601	13579.57171	590.242857	-0.998715	-0.000035	19790.625
stats.plot()
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_31_0.png
stats.plot()
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_32_0.png
Adjustment factors
It looks like the skew is too strong, which is why the market maker is hesitant to take on the position. To alleviate the skew, you can introduce adjustment factors, 
 and 
, to the calculated half spread and skew, as follow.

 
from numba.typed import Dict

@njit
def glft_market_maker(hbt, recorder):
    tick_size = hbt.depth(0).tick_size
    arrival_depth = np.full(10_000_000, np.nan, np.float64)
    mid_price_chg = np.full(10_000_000, np.nan, np.float64)
    out = np.zeros(10_000_000, out_dtype)

    t = 0
    prev_mid_price_tick = np.nan
    mid_price_tick = np.nan

    tmp = np.zeros(500, np.float64)
    ticks = np.arange(len(tmp)) + 0.5

    A = np.nan
    k = np.nan
    volatility = np.nan
    gamma = 0.05
    delta = 1
    adj1 = 1
    adj2 = 0.05 # Uses the same value as gamma.

    order_qty = 1
    max_position = 20

    # Checks every 100 milliseconds.
    while hbt.elapse(100_000_000) == 0:
        #--------------------------------------------------------
        # Records market order's arrival depth from the mid-price.
        if not np.isnan(mid_price_tick):
            depth = -np.inf
            for last_trade in hbt.last_trades(0):
                trade_price_tick = last_trade.px / tick_size

                if last_trade.ev & BUY_EVENT == BUY_EVENT:
                    depth = np.nanmax([trade_price_tick - mid_price_tick, depth])
                else:
                    depth = np.nanmax([mid_price_tick - trade_price_tick, depth])
            arrival_depth[t] = depth

        hbt.clear_last_trades(0)
        hbt.clear_inactive_orders(0)

        depth = hbt.depth(0)
        position = hbt.position(0)
        orders = hbt.orders(0)

        best_bid_tick = depth.best_bid_tick
        best_ask_tick = depth.best_ask_tick

        prev_mid_price_tick = mid_price_tick
        mid_price_tick = (best_bid_tick + best_ask_tick) / 2.0

        # Records the mid-price change for volatility calculation.
        mid_price_chg[t] = mid_price_tick - prev_mid_price_tick

        #--------------------------------------------------------
        # Calibrates A, k and calculates the market volatility.

        # Updates A, k, and the volatility every 5-sec.
        if t % 50 == 0:
            # Window size is 10-minute.
            if t >= 6_000 - 1:
                # Calibrates A, k
                tmp[:] = 0
                lambda_ = measure_trading_intensity(arrival_depth[t + 1 - 6_000:t + 1], tmp)
                if len(lambda_) > 2:
                    lambda_ = lambda_[:70] / 600
                    x = ticks[:len(lambda_)]
                    y = np.log(lambda_)
                    k_, logA = linear_regression(x, y)
                    A = np.exp(logA)
                    k = -k_

                # Updates the volatility.
                volatility = np.nanstd(mid_price_chg[t + 1 - 6_000:t + 1]) * np.sqrt(10)

        #--------------------------------------------------------
        # Computes bid price and ask price.

        c1, c2 = compute_coeff(gamma, gamma, delta, A, k)

        half_spread_tick = (c1 + delta / 2 * c2 * volatility) * adj1
        skew = c2 * volatility * adj2

        reservation_price_tick = mid_price_tick - skew * position

        bid_price_tick = np.minimum(np.round(reservation_price_tick - half_spread_tick), best_bid_tick)
        ask_price_tick = np.maximum(np.round(reservation_price_tick + half_spread_tick), best_ask_tick)

        bid_price = bid_price_tick * tick_size
        ask_price = ask_price_tick * tick_size

        #--------------------------------------------------------
        # Updates quotes.

        # Cancel orders if they differ from the updated bid and ask prices.
        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.price_tick != bid_price_tick)
                    or (order.side == SELL and order.price_tick != ask_price_tick)
                ):
                    hbt.cancel(0, order.order_id, False)

        # If the current position is within the maximum position,
        # submit the new order only if no order exists at the same price.
        if position < max_position and np.isfinite(bid_price):
            bid_price_as_order_id = round(bid_price / tick_size)
            if bid_price_as_order_id not in orders:
                hbt.submit_buy_order(0, bid_price_as_order_id, bid_price, order_qty, GTX, LIMIT, False)
        if position > -max_position and np.isfinite(ask_price):
            ask_price_as_order_id = round(ask_price / tick_size)
            if ask_price_as_order_id not in orders:
                hbt.submit_sell_order(0, ask_price_as_order_id, ask_price, order_qty, GTX, LIMIT, False)

        #--------------------------------------------------------
        # Records variables and stats for analysis.

        out[t].half_spread_tick = half_spread_tick
        out[t].skew = skew
        out[t].volatility = volatility
        out[t].A = A
        out[t].k = k

        t += 1

        if t >= len(arrival_depth) or t >= len(mid_price_chg) or t >= len(out):
            raise Exception

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return out[:t]
asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20221003.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20221003.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

out = glft_market_maker(hbt, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=30_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-03 23:59:50	1.202048	1.471295	0.000359	0.004763	10987.271675	477.498424	0.075478	7.5295e-7	27563.655
stats.plot()
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_36_0.png
Improved, but even when accounting for rebates, it can only achieve breakeven at best. As shown below, both the half spread and skew move together, primarily influenced by the 
 and the market volatility.

import polars as pl

records = recorder.get(0)
df = pl.DataFrame(out).with_columns(
    pl.Series('timestamp', records['timestamp']),
    pl.Series('price', records['price'])
).with_columns(
    pl.from_epoch('timestamp', time_unit='ns')
)

df = df.group_by_dynamic(
    'timestamp', every='5m'
).agg(
    pl.col('price').last(),
    pl.col('half_spread_tick').last(),
    pl.col('skew').last(),
    pl.col('volatility').last(),
    pl.col('A').last(),
    pl.col('k').last(),
)

fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)
fig.subplots_adjust(hspace=0)
fig.set_size_inches(10, 6)

ax1.plot(df['timestamp'], df['half_spread_tick'])
ax1.twinx().plot(df['timestamp'], df['price'], 'r')
ax1.set_ylabel('Half spread (tick)')

ax2.plot(df['timestamp'], df['skew'])
ax2.twinx().plot(df['timestamp'], df['price'], 'r')
ax2.set_ylabel('Skew (tick)')
Text(0, 0.5, 'Skew (tick)')
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_38_1.png
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True)
fig.subplots_adjust(hspace=0)
fig.set_size_inches(10, 9)

ax1.plot(df['timestamp'], df['volatility'])
ax1.twinx().plot(df['timestamp'], df['price'], 'r')
ax1.set_ylabel('Volatility ($ tick/s^{1/2} $)')

ax2.plot(df['timestamp'], df['A'])
ax2.twinx().plot(df['timestamp'], df['price'], 'r')
ax2.set_ylabel('A ($ s^{-1} $)')

ax3.plot(df['timestamp'], df['k'])
ax3.twinx().plot(df['timestamp'], df['price'], 'r')
ax3.set_ylabel('k ($ tick^{-1} $)')
Text(0, 0.5, 'k ($ tick^{-1} $)')
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_39_1.png
In the 5-day backtest, it’s evident that profits are generated through rebates, as a result of maintaining high trading volume by consistently posting quotes.

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20221003.npz',
            'data/ethusdt_20221004.npz',
            'data/ethusdt_20221005.npz',
            'data/ethusdt_20221006.npz',
            'data/ethusdt_20221007.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20221003.npz',
            'latency/feed_latency_20221004.npz',
            'latency/feed_latency_20221005.npz',
            'latency/feed_latency_20221006.npz',
            'latency/feed_latency_20221007.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

out = glft_market_maker(hbt, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=30_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-07 23:59:50	16.282366	20.682178	0.031145	0.009818	9463.81907	422.448163	3.172133	0.000015	34458.375
stats.plot()
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_42_0.png
Integrating Grid Trading
Creating a grid from the bid and ask prices derived from the Guéant–Lehalle–Fernandez-Tapia market making model.

from numba.typed import Dict
from numba import uint64

@njit
def gridtrading_glft_mm(hbt, recorder):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size

    arrival_depth = np.full(10_000_000, np.nan, np.float64)
    mid_price_chg = np.full(10_000_000, np.nan, np.float64)

    t = 0
    prev_mid_price_tick = np.nan
    mid_price_tick = np.nan

    tmp = np.zeros(500, np.float64)
    ticks = np.arange(len(tmp)) + 0.5

    A = np.nan
    k = np.nan
    volatility = np.nan
    gamma = 0.05
    delta = 1
    adj1 = 1
    adj2 = 0.05

    order_qty = 1
    max_position = 20
    grid_num = 20

    # Checks every 100 milliseconds.
    while hbt.elapse(100_000_000) == 0:
        #--------------------------------------------------------
        # Records market order's arrival depth from the mid-price.
        if not np.isnan(mid_price_tick):
            depth = -np.inf
            for last_trade in hbt.last_trades(asset_no):
                trade_price_tick = last_trade.px / tick_size

                if last_trade.ev & BUY_EVENT == BUY_EVENT:
                    depth = np.nanmax([trade_price_tick - mid_price_tick, depth])
                else:
                    depth = np.nanmax([mid_price_tick - trade_price_tick, depth])
            arrival_depth[t] = depth

        hbt.clear_last_trades(asset_no)
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid_tick = depth.best_bid_tick
        best_ask_tick = depth.best_ask_tick

        prev_mid_price_tick = mid_price_tick
        mid_price_tick = (best_bid_tick + best_ask_tick) / 2.0

        # Records the mid-price change for volatility calculation.
        mid_price_chg[t] = mid_price_tick - prev_mid_price_tick

        #--------------------------------------------------------
        # Calibrates A, k and calculates the market volatility.

        # Updates A, k, and the volatility every 5-sec.
        if t % 50 == 0:
            # Window size is 10-minute.
            if t >= 6_000 - 1:
                # Calibrates A, k
                tmp[:] = 0
                lambda_ = measure_trading_intensity(arrival_depth[t + 1 - 6_000:t + 1], tmp)
                if len(lambda_) > 2:
                    lambda_ = lambda_[:70] / 600
                    x = ticks[:len(lambda_)]
                    y = np.log(lambda_)
                    k_, logA = linear_regression(x, y)
                    A = np.exp(logA)
                    k = -k_

                # Updates the volatility.
                volatility = np.nanstd(mid_price_chg[t + 1 - 6_000:t + 1]) * np.sqrt(10)

        #--------------------------------------------------------
        # Computes bid price and ask price.

        c1, c2 = compute_coeff(gamma, gamma, delta, A, k)

        half_spread_tick = (c1 + delta / 2 * c2 * volatility) * adj1
        skew = c2 * volatility * adj2

        reservation_price_tick = mid_price_tick - skew * position

        bid_price_tick = np.minimum(np.round(reservation_price_tick - half_spread_tick), best_bid_tick)
        ask_price_tick = np.maximum(np.round(reservation_price_tick + half_spread_tick), best_ask_tick)

        bid_price = bid_price_tick * tick_size
        ask_price = ask_price_tick * tick_size

        grid_interval = max(np.round(half_spread_tick) * tick_size, tick_size)

        bid_price = np.floor(bid_price / grid_interval) * grid_interval
        ask_price = np.ceil(ask_price / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if position < max_position and np.isfinite(bid_price):
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if position > -max_position and np.isfinite(ask_price):
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        #--------------------------------------------------------
        # Records variables and stats for analysis.

        t += 1

        if t >= len(arrival_depth) or t >= len(mid_price_chg):
            raise Exception

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return out[:t]
asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20221003.npz',
            'data/ethusdt_20221004.npz',
            'data/ethusdt_20221005.npz',
            'data/ethusdt_20221006.npz',
            'data/ethusdt_20221007.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20221003.npz',
            'latency/feed_latency_20221004.npz',
            'latency/feed_latency_20221005.npz',
            'latency/feed_latency_20221006.npz',
            'latency/feed_latency_20221007.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

out = gridtrading_glft_mm(hbt, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=30_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-07 23:59:50	19.774661	24.630456	0.055856	0.007438	5878.736082	262.524795	7.509437	0.000043	30859.215
stats.plot()
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_46_0.png
You can see it works even better with other coins as well. In the next example, we will show how to create multiple markets to achieve better risk-adjusted returns.

asset = (
    BacktestAsset()
        .data([
            'data/ltcusdt_20230701.npz',
            'data/ltcusdt_20230702.npz',
            'data/ltcusdt_20230703.npz',
            'data/ltcusdt_20230704.npz',
            'data/ltcusdt_20230705.npz'
        ])
        .initial_snapshot('data/ltcusdt_20230630_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20230701.npz',
            'latency/feed_latency_20230702.npz',
            'latency/feed_latency_20230703.npz',
            'latency/feed_latency_20230704.npz',
            'latency/feed_latency_20230705.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(300.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

out = gridtrading_glft_mm(hbt, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=3000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2023-07-01 00:00:00	2023-07-05 23:59:50	17.17992	23.062973	0.122535	0.032973	3425.879303	122.800909	3.716196	0.0002	2930.06
stats.plot()
../_images/tutorials_GLFT_Market_Making_Model_and_Grid_Trading_49_0.png
Wrapping up
Thus far, we have illustrated how to apply the model to a real-world example.

For a more effective market-making algorithm, consider dividing this model into the following categories:

Half-spread: As shown, the half-spread is a function of trading intensity and market volatility. An exponential function used for trading intensity might not be suitable for the entire range. You could develop a more refined approach to convert trading intensity to half-spread. Additionally, while historical trading intensity and market volatility are utilized here, you could forecast short-term trading intensity and volatility to respond more agilely to changes in market conditions. This might involve strategies that use news, events, liquidity vacuums, and other factors to predict volatility explosions.

Skew: The skew is also a function of trading intensity and market volatility. In this model, only inventory risk is considered, but you can also account for other risks, particularly when making multiple markets. BARRA is a good example of other risks that can be managed similarly.

Fair Value Pricing: In this model, the fair price is equal to the mid-price, however, you need to incorporate forecasts such as the micro-price and fair value pricing through correlated assets to enhance the strategy.

Hedging: Hedging is especially crucial when making multiple markets, as it serves as a valuable tool for managing risks.

We will address a few more topics in upcoming examples.

References
Dealing with the Inventory Risk - A solution to the market making problem
Optimal market making
Knight Capital Group
Stochastic Control Theory and High Frequency Trading
BitMEX Market Making Series
Algo Trading & Market Making
How to Market Make Bitcoin Derivatives Lesson 1
How to Market Make Bitcoin Derivatives Lesson 2

© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Display 3-depth
Efficient Market Depth Access
Order Book Imbalance
Display last trades between the step
Rolling Volume-Weighted Average Price
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Ensure the availability of your data with coverage across AWS, Azure, and GCP on MongoDB Atlas.
Ads by EthicalAds
Close Ad
 Working with Market Depth and TradesView page source
Working with Market Depth and Trades
Display 3-depth
from numba import njit

@njit
def print_3depth(hbt):
    while hbt.elapse(60_000_000_000) == 0:
        print('current_timestamp:', hbt.current_timestamp)

        # Gets the market depth for the first asset, in the same order as when you created the backtest.
        depth = hbt.depth(0)

        # a key of bid_depth or ask_depth is price in ticks.
        # (integer) price_tick = rice / tick_size
        i = 0
        for price_tick in range(depth.best_ask_tick, depth.best_ask_tick + 100):
            qty = depth.ask_qty_at_tick(price_tick)
            if qty > 0:
                print(
                    'ask: ',
                    qty,
                    '@',
                    np.round(price_tick * depth.tick_size, 1)
                )

                i += 1
                if i == 3:
                    break
        i = 0
        for price_tick in range(depth.best_bid_tick, max(depth.best_bid_tick - 100, 0), -1):
            qty = depth.bid_qty_at_tick(price_tick)
            if qty > 0:
                print(
                    'bid: ',
                    qty,
                    '@',
                    np.round(price_tick * depth.tick_size, 1)
                )

                i += 1
                if i == 3:
                    break
    return True
import numpy as np

btcusdt_20240809 = np.load('usdm/btcusdt_20240809.npz')['data']
btcusdt_20240808_eod = np.load('usdm/btcusdt_20240808_eod.npz')['data']
from hftbacktest import BacktestAsset, HashMapMarketDepthBacktest

asset = (
    BacktestAsset()
        .data(btcusdt_20240809)
        .initial_snapshot(btcusdt_20240808_eod)
        .linear_asset(1.0)
        .constant_latency(10_000_000, 10_000_000)
        .risk_adverse_queue_model()
        .no_partial_fill_exchange()
        .trading_value_fee_model(0.0002, 0.0007)
        .tick_size(0.1)
        .lot_size(0.001)
)

hbt = HashMapMarketDepthBacktest([asset])

print_3depth(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000
ask:  1.759 @ 61594.2
ask:  0.006 @ 61594.4
ask:  0.114 @ 61595.2
bid:  3.526 @ 61594.1
bid:  0.016 @ 61594.0
bid:  0.002 @ 61593.9
current_timestamp: 1723161721500000000
ask:  2.575 @ 61576.6
ask:  0.004 @ 61576.7
ask:  0.455 @ 61577.0
bid:  2.558 @ 61576.5
bid:  0.002 @ 61576.0
bid:  0.515 @ 61575.5
current_timestamp: 1723161781500000000
ask:  0.131 @ 61629.7
ask:  0.005 @ 61630.1
ask:  0.005 @ 61630.5
bid:  5.742 @ 61629.6
bid:  0.247 @ 61629.4
bid:  0.034 @ 61629.3
current_timestamp: 1723161841500000000
ask:  0.202 @ 61621.6
ask:  0.002 @ 61622.5
ask:  0.003 @ 61622.6
bid:  3.488 @ 61621.5
bid:  0.86 @ 61620.0
bid:  0.248 @ 61619.6
current_timestamp: 1723161901500000000
ask:  1.397 @ 61584.0
ask:  0.832 @ 61585.1
ask:  0.132 @ 61586.0
bid:  3.307 @ 61583.9
bid:  0.01 @ 61583.8
bid:  0.002 @ 61582.0
Efficient Market Depth Access
ROIVectorMarketDepth provides more efficient market depth access through a vector that holds a limited price range of interest. The backtester using this feature can be created by ROIVectorMarketDepthBacktest.

from numba import njit

@njit
def print_3depth_fast(hbt):
    roi_lb_tick = int(round(30000 / 0.1))
    roi_ub_tick = int(round(90000 / 0.1))

    while hbt.elapse(60_000_000_000) == 0:
        print('current_timestamp:', hbt.current_timestamp)

        # Gets the market depth for the first asset, in the same order as when you created the backtest.
        depth = hbt.depth(0)

        # a key of bid_depth or ask_depth is price in ticks.
        # (integer) price_tick = price / tick_size
        i = 0
        for price_tick in range(depth.best_ask_tick, depth.best_ask_tick + 100):
            # depth.ask_depth returns the ask depth array, whose length is (roi_ub_tick + 1 - roi_lb_tick),
            # containing the quantities ranging from roi_lb_tick to roi_ub_tick.
            # Checks that the price_tick is in that range and adjust the index by subtracting roi_lb_tick.
            if price_tick < roi_lb_tick or price_tick > roi_ub_tick:
                continue
            t = price_tick - roi_lb_tick
            qty = depth.ask_depth[t]
            if qty > 0:
                print(
                    'ask: ',
                    qty,
                    '@',
                    np.round(price_tick * depth.tick_size, 1)
                )

                i += 1
                if i == 3:
                    break
        i = 0
        for price_tick in range(depth.best_bid_tick, max(depth.best_bid_tick - 100, 0), -1):
            # depth.bid_depth returns the bid depth array, whose length is (roi_ub_tick + 1 - roi_lb_tick),
            # containing the quantities ranging from roi_lb_tick to roi_ub_tick.
            # Checks that the price_tick is in that range and adjust the index by subtracting roi_lb_tick.
            if price_tick < roi_lb_tick or price_tick > roi_ub_tick:
                continue
            t = price_tick - roi_lb_tick
            qty = depth.bid_depth[t]
            if qty > 0:
                print(
                    'bid: ',
                    qty,
                    '@',
                    np.round(price_tick * depth.tick_size, 1)
                )

                i += 1
                if i == 3:
                    break
    return True
from hftbacktest import ROIVectorMarketDepthBacktest

asset = (
    BacktestAsset()
        .data(btcusdt_20240809)
        .initial_snapshot(btcusdt_20240808_eod)
        .linear_asset(1.0)
        .constant_latency(10_000_000, 10_000_000)
        .risk_adverse_queue_model()
        .no_partial_fill_exchange()
        .trading_value_fee_model(0.0002, 0.0007)
        .tick_size(0.1)
        .lot_size(0.001)
        # Sets the lower bound price for the range of interest in the market depth.
        .roi_lb(30000)
        # Sets the upper bound price for the range of interest in the market depth.
        .roi_ub(90000)
)


hbt = ROIVectorMarketDepthBacktest([asset])

print_3depth_fast(hbt)

_ = hbt.close()
current_timestamp: 1723161661500000000
ask:  1.759 @ 61594.2
ask:  0.006 @ 61594.4
ask:  0.114 @ 61595.2
bid:  3.526 @ 61594.1
bid:  0.016 @ 61594.0
bid:  0.002 @ 61593.9
current_timestamp: 1723161721500000000
ask:  2.575 @ 61576.6
ask:  0.004 @ 61576.7
ask:  0.455 @ 61577.0
bid:  2.558 @ 61576.5
bid:  0.002 @ 61576.0
bid:  0.515 @ 61575.5
current_timestamp: 1723161781500000000
ask:  0.131 @ 61629.7
ask:  0.005 @ 61630.1
ask:  0.005 @ 61630.5
bid:  5.742 @ 61629.6
bid:  0.247 @ 61629.4
bid:  0.034 @ 61629.3
current_timestamp: 1723161841500000000
ask:  0.202 @ 61621.6
ask:  0.002 @ 61622.5
ask:  0.003 @ 61622.6
bid:  3.488 @ 61621.5
bid:  0.86 @ 61620.0
bid:  0.248 @ 61619.6
current_timestamp: 1723161901500000000
ask:  1.397 @ 61584.0
ask:  0.832 @ 61585.1
ask:  0.132 @ 61586.0
bid:  3.307 @ 61583.9
bid:  0.01 @ 61583.8
bid:  0.002 @ 61582.0
Order Book Imbalance
@njit
def orderbookimbalance(hbt, out):
    roi_lb_tick = int(round(30000 / 0.1))
    roi_ub_tick = int(round(90000 / 0.1))

    while hbt.elapse(10 * 1e9) == 0:
        depth = hbt.depth(0)

        mid_price = (depth.best_bid + depth.best_ask) / 2.0

        sum_ask_qty_50bp = 0.0
        sum_ask_qty = 0.0
        for price_tick in range(depth.best_ask_tick, roi_ub_tick + 1):
            if price_tick < roi_lb_tick or price_tick > roi_ub_tick:
                continue
            t = price_tick - roi_lb_tick

            ask_price = price_tick * depth.tick_size
            depth_from_mid = (ask_price - mid_price) / mid_price
            if depth_from_mid > 0.01:
                break
            sum_ask_qty += depth.ask_depth[t]

            if depth_from_mid <= 0.005:
                sum_ask_qty_50bp = sum_ask_qty


        sum_bid_qty_50bp = 0.0
        sum_bid_qty = 0.0
        for price_tick in range(depth.best_bid_tick, roi_lb_tick - 1, -1):
            if price_tick < roi_lb_tick or price_tick > roi_ub_tick:
                continue
            t = price_tick - roi_lb_tick

            bid_price = price_tick * depth.tick_size
            depth_from_mid = (mid_price - bid_price) / mid_price
            if depth_from_mid > 0.01:
                break
            sum_bid_qty += depth.bid_depth[t]

            if depth_from_mid <= 0.005:
                sum_bid_qty_50bp = sum_bid_qty

        imbalance_50bp = sum_bid_qty_50bp - sum_ask_qty_50bp
        imbalance_1pct = sum_bid_qty - sum_ask_qty
        imbalance_tob = depth.bid_depth[depth.best_bid_tick - roi_lb_tick] - depth.ask_depth[depth.best_ask_tick - roi_lb_tick]

        out.append((hbt.current_timestamp, imbalance_tob, imbalance_50bp, imbalance_1pct))
    return True
from numba.typed import List
from numba.types import Tuple, float64

hbt = ROIVectorMarketDepthBacktest([asset])

tup_ty = Tuple((float64, float64, float64, float64))
out = List.empty_list(tup_ty, allocated=100_000)

orderbookimbalance(hbt, out)

_ = hbt.close()
import polars as pl

df = pl.DataFrame(out).transpose()
df.columns = ['Local Timestamp', 'TOB Imbalance', '0.5% Imbalance', '1% Imbalance']
df = df.with_columns(
    pl.from_epoch('Local Timestamp', time_unit='ns')
)

df
shape: (30, 4)
Local Timestamp	TOB Imbalance	0.5% Imbalance	1% Imbalance
datetime[ns]	f64	f64	f64
2024-08-09 00:00:11.500	2.729	-1748.101	-3908.736
2024-08-09 00:00:21.500	4.623	-1749.435	-3512.845
2024-08-09 00:00:31.500	-6.465	-1259.897	-3357.755
2024-08-09 00:00:41.500	-7.922	-1174.185	-3471.955
2024-08-09 00:00:51.500	-2.484	-1147.597	-3461.48
…	…	…	…
2024-08-09 00:04:21.500	3.828	-1186.236	-3551.78
2024-08-09 00:04:31.500	-1.35	-1332.379	-3517.854
2024-08-09 00:04:41.500	-3.754	-1166.521	-2693.672
2024-08-09 00:04:51.500	-2.525	-1188.56	-2716.914
2024-08-09 00:05:01.500	1.91	-594.991	-2138.82
from matplotlib import pyplot

pyplot.plot(df['Local Timestamp'], df['TOB Imbalance'])
pyplot.plot(df['Local Timestamp'], df['0.5% Imbalance'])
pyplot.plot(df['Local Timestamp'], df['1% Imbalance'])
[<matplotlib.lines.Line2D at 0x7f01eaf10520>]
../_images/tutorials_Working_with_Market_Depth_and_Trades_13_1.png
Display last trades between the step
from hftbacktest import BUY_EVENT

@njit
def print_trades(hbt):
    while hbt.elapse(60 * 1e9) == 0:
        print('-------------------------------------------------------------------------------')
        print('current_timestamp:', hbt.current_timestamp)

        # Gets the last trades occurring in the market, not the trades of our orders.
        last_trades = hbt.last_trades(0)

        num = 0
        for last_trade in last_trades:
            if num > 10:
                print('...')
                break
            print(
                'exch_timestamp:',
                last_trade.exch_ts,
                'buy' if (last_trade.ev & BUY_EVENT) == BUY_EVENT else 'sell',
                last_trade.qty,
                '@',
                last_trade.px
            )
            num += 1

        # To prevent accumulating all last trades, which may cause a slowdown,
        # clear_last_trades needs to be called.
        # After this, accessing `last_trades` will cause a crash.
        hbt.clear_last_trades(0)
    return True
asset = (
    BacktestAsset()
        .data(btcusdt_20240809)
        .initial_snapshot(btcusdt_20240808_eod)
        .linear_asset(1.0)
        .constant_latency(10_000_000, 10_000_000)
        .risk_adverse_queue_model()
        .no_partial_fill_exchange()
        .trading_value_fee_model(0.0002, 0.0007)
        .tick_size(0.1)
        .lot_size(0.001)
        # To retrieve the last trades, `last_trades_capacity` should be set.
        .last_trades_capacity(1000)
        .roi_lb(30000)
        .roi_ub(90000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

print_trades(hbt)

_ = hbt.close()
-------------------------------------------------------------------------------
current_timestamp: 1723161661500000000
exch_timestamp: 1723161602372000000 buy 0.489 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.198 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.006 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.002 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.003 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.011 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.238 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.007 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.005 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.003 @ 61659.8
exch_timestamp: 1723161602372000000 buy 0.002 @ 61659.8
...
-------------------------------------------------------------------------------
current_timestamp: 1723161721500000000
exch_timestamp: 1723161661697000000 sell 0.002 @ 61594.1
exch_timestamp: 1723161661724000000 sell 0.002 @ 61594.1
exch_timestamp: 1723161661751000000 buy 0.135 @ 61594.2
exch_timestamp: 1723161661806000000 sell 1.328 @ 61594.1
exch_timestamp: 1723161661806000000 sell 0.002 @ 61594.1
exch_timestamp: 1723161661806000000 sell 0.002 @ 61594.1
exch_timestamp: 1723161661806000000 sell 0.002 @ 61594.1
exch_timestamp: 1723161661806000000 sell 0.006 @ 61594.1
exch_timestamp: 1723161661806000000 sell 0.32 @ 61594.1
exch_timestamp: 1723161661806000000 sell 0.032 @ 61594.1
exch_timestamp: 1723161661806000000 sell 1.208 @ 61594.1
...
-------------------------------------------------------------------------------
current_timestamp: 1723161781500000000
exch_timestamp: 1723161721541000000 sell 0.002 @ 61576.5
exch_timestamp: 1723161721574000000 buy 0.012 @ 61576.6
exch_timestamp: 1723161721578000000 sell 0.003 @ 61576.5
exch_timestamp: 1723161721583000000 buy 0.275 @ 61576.6
exch_timestamp: 1723161721583000000 buy 0.469 @ 61576.6
exch_timestamp: 1723161721585000000 buy 0.095 @ 61576.6
exch_timestamp: 1723161721585000000 buy 0.102 @ 61576.6
exch_timestamp: 1723161721585000000 buy 0.197 @ 61576.6
exch_timestamp: 1723161721586000000 buy 0.13 @ 61576.6
exch_timestamp: 1723161721587000000 buy 0.425 @ 61576.6
exch_timestamp: 1723161721587000000 buy 0.324 @ 61576.6
...
-------------------------------------------------------------------------------
current_timestamp: 1723161841500000000
exch_timestamp: 1723161781628000000 sell 0.026 @ 61629.6
exch_timestamp: 1723161781727000000 buy 0.011 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.05 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.006 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.002 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.007 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.002 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.075 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.065 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.247 @ 61629.7
exch_timestamp: 1723161781727000000 buy 0.002 @ 61629.7
...
-------------------------------------------------------------------------------
current_timestamp: 1723161901500000000
exch_timestamp: 1723161841561000000 buy 0.01 @ 61621.6
exch_timestamp: 1723161841561000000 buy 0.006 @ 61621.6
exch_timestamp: 1723161841561000000 buy 0.002 @ 61621.6
exch_timestamp: 1723161841561000000 buy 0.022 @ 61621.6
exch_timestamp: 1723161841561000000 buy 0.097 @ 61621.6
exch_timestamp: 1723161841561000000 buy 0.024 @ 61621.6
exch_timestamp: 1723161841564000000 buy 0.024 @ 61621.6
exch_timestamp: 1723161841564000000 buy 0.014 @ 61621.6
exch_timestamp: 1723161841565000000 buy 0.003 @ 61621.6
exch_timestamp: 1723161841613000000 buy 0.002 @ 61622.5
exch_timestamp: 1723161841613000000 buy 0.003 @ 61622.6
...
Rolling Volume-Weighted Average Price
@njit
def rolling_vwap(hbt, out):
    buy_amount_bin = np.zeros(100_000, np.float64)
    buy_qty_bin = np.zeros(100_000, np.float64)
    sell_amount_bin = np.zeros(100_000, np.float64)
    sell_qty_bin = np.zeros(100_000, np.float64)

    idx = 0
    last_trade_price = np.nan

    while hbt.elapse(10 * 1e9) == 0:
        last_trades = hbt.last_trades(0)

        for last_trade in last_trades:
            if (last_trade.ev & BUY_EVENT) == BUY_EVENT:
                buy_amount_bin[idx] += last_trade.px * last_trade.qty
                buy_qty_bin[idx] += last_trade.qty
            else:
                sell_amount_bin[idx] += last_trade.px * last_trade.qty
                sell_qty_bin[idx] += last_trade.qty

        hbt.clear_last_trades(0)
        idx += 1

        if idx >= 1:
            vwap10sec = np.divide(
                buy_amount_bin[idx - 1] + sell_amount_bin[idx - 1],
                buy_qty_bin[idx - 1] + sell_qty_bin[idx - 1]
            )
        else:
            vwap10sec = np.nan

        if idx >= 6:
            vwap1m = np.divide(
                np.sum(buy_amount_bin[idx - 6:idx]) + np.sum(sell_amount_bin[idx - 6:idx]),
                np.sum(buy_qty_bin[idx - 6:idx]) + np.sum(sell_qty_bin[idx - 6:idx])
            )
            buy_vwap1m = np.divide(np.sum(buy_amount_bin[idx - 6:idx]), np.sum(buy_qty_bin[idx - 6:idx]))
            sell_vwap1m = np.divide(np.sum(sell_amount_bin[idx - 6:idx]), np.sum(sell_qty_bin[idx - 6:idx]))
        else:
            vwap1m = np.nan
            buy_vwap1m = np.nan
            sell_vwap1m = np.nan

        out.append((hbt.current_timestamp, vwap10sec, vwap1m, buy_vwap1m, sell_vwap1m))
    return True
hbt = ROIVectorMarketDepthBacktest([asset])

tup_ty = Tuple((float64, float64, float64, float64, float64))
out = List.empty_list(tup_ty, allocated=100_000)

rolling_vwap(hbt, out)

_ = hbt.close()
df = pl.DataFrame(out).transpose()
df.columns = ['Local Timestamp', '10-sec VWAP', '1-min VWAP', '1-min Buy VWAP', '1-min Sell VWAP']
df = df.with_columns(
    pl.from_epoch('Local Timestamp', time_unit='ns')
)

df
shape: (30, 5)
Local Timestamp	10-sec VWAP	1-min VWAP	1-min Buy VWAP	1-min Sell VWAP
datetime[ns]	f64	f64	f64	f64
2024-08-09 00:00:11.500	61687.182976	NaN	NaN	NaN
2024-08-09 00:00:21.500	61709.337576	NaN	NaN	NaN
2024-08-09 00:00:31.500	61697.538054	NaN	NaN	NaN
2024-08-09 00:00:41.500	61663.958879	NaN	NaN	NaN
2024-08-09 00:00:51.500	61637.340621	NaN	NaN	NaN
…	…	…	…	…
2024-08-09 00:04:21.500	61643.009847	61624.459011	61626.495542	61622.549429
2024-08-09 00:04:31.500	61670.795685	61635.877251	61638.362314	61632.48854
2024-08-09 00:04:41.500	61643.108582	61641.846489	61648.672337	61636.032054
2024-08-09 00:04:51.500	61614.723569	61640.490841	61647.769844	61634.372128
2024-08-09 00:05:01.500	61584.697467	61637.334102	61642.209551	61632.12064
pyplot.plot(df['Local Timestamp'], df['10-sec VWAP'])
pyplot.plot(df['Local Timestamp'], df['1-min VWAP'])
pyplot.plot(df['Local Timestamp'], df['1-min Buy VWAP'])
pyplot.plot(df['Local Timestamp'], df['1-min Sell VWAP'])
[<matplotlib.lines.Line2D at 0x7f01b995e0b0>]
../_images/tutorials_Working_with_Market_Depth_and_Trades_21_1.png
© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Accessing Spot Price
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
The AI Agent that gets your codebase Copilot & Cursor letting you down? Try Augment. Install Now
Ads by EthicalAds
Close Ad
 Integrating Custom DataView page source
Integrating Custom Data
By combining your custom data with the feed data (order book and trades), you can enhance your strategy while harnessing the full potential of hftbacktest.

Accessing Spot Price
In this example, we’ll combine the spot BTCUSDT mid-price with the USDM-Futures BTCUSDT feed data. This will enable you to estimate the fair value price, taking the underlying price into consideration.

The spot data is used only in the local-side, and thus, should come with a local timestamp. Following this, in your backtesting logic, your task is to identify the most recent data that predates the current timestamp.

The raw spot feed is processed to create spot data, which includes both a local timestamp and the spot mid price.

import numpy as np
import gzip
import json

spot = np.full((100_000, 2), np.nan, np.float64)
i = 0

with gzip.open('spot/btcusdt_20240809.gz', 'r') as f:
    while True:
        line = f.readline()
        if line is None or line == b'':
            break

        line = line.decode().strip()
        local_timestamp = int(line[:19])

        obj = json.loads(line[20:])
        if obj['stream'] == 'btcusdt@bookTicker':
            data = obj['data']
            mid = (float(data['b']) + float(data['a'])) / 2.0
            spot[i] = [local_timestamp, mid]
            i += 1

spot = spot[:i]
It displays the basis and spot mid price as it identifies the latest Point-in-Time data that falls before the current timestamp.

from numba import njit
from hftbacktest import BacktestAsset, HashMapMarketDepthBacktest

out_dtype = np.dtype([('timestamp', 'i8'), ('mid_price', 'f8'), ('spot_mid_price', 'f8')])

@njit
def print_basis(hbt, spot):
    out = np.empty(1_000_000, out_dtype)

    t = 0
    spot_row = 0

    # Checks every 60-sec (in nanoseconds)
    while hbt.elapse(1_000_000_000) == 0:
        # Finds the latest spot mid value.
        while spot_row < len(spot) and spot[spot_row, 0] <= hbt.current_timestamp:
            spot_row += 1
        spot_mid_price = spot[spot_row - 1, 1] if spot_row > 0 else np.nan

        depth = hbt.depth(0)

        mid_price = (depth.best_bid + depth.best_ask) / 2.0
        basis = mid_price - spot_mid_price

        if t % 10 == 0:
            print(
                'current_timestamp:',
                hbt.current_timestamp,
                'futures_mid:',
                round(mid_price, 2),
                ', spot_mid:',
                round(spot_mid_price, 2),
                ', basis:',
                round(basis, 2)
            )

        out[t].timestamp = hbt.current_timestamp
        out[t].mid_price = mid_price
        out[t].spot_mid_price = spot_mid_price
        t += 1

    return out[:t]

asset = (
    BacktestAsset()
        .data(['usdm/btcusdt_20240809.npz'])
        .initial_snapshot('usdm/btcusdt_20240808_eod.npz')
        .linear_asset(1.0)
        .constant_latency(10_000_000, 10_000_000)
        .risk_adverse_queue_model()
        .no_partial_fill_exchange()
        .trading_value_fee_model(0.0002, 0.0007)
        .tick_size(0.1)
        .lot_size(0.001)
)

hbt = HashMapMarketDepthBacktest([asset])

out = print_basis(hbt, spot)

_ = hbt.close()
current_timestamp: 1723161602500000000 futures_mid: 61659.85 , spot_mid: 61688.0 , basis: -28.14
current_timestamp: 1723161612500000000 futures_mid: 61713.95 , spot_mid: 61727.8 , basis: -13.85
current_timestamp: 1723161622500000000 futures_mid: 61713.45 , spot_mid: 61728.94 , basis: -15.5
current_timestamp: 1723161632500000000 futures_mid: 61666.05 , spot_mid: 61690.08 , basis: -24.02
current_timestamp: 1723161642500000000 futures_mid: 61638.45 , spot_mid: 61661.5 , basis: -23.06
current_timestamp: 1723161652500000000 futures_mid: 61632.05 , spot_mid: 61663.98 , basis: -31.93
current_timestamp: 1723161662500000000 futures_mid: 61578.15 , spot_mid: 61600.0 , basis: -21.85
current_timestamp: 1723161672500000000 futures_mid: 61524.25 , spot_mid: 61562.0 , basis: -37.74
current_timestamp: 1723161682500000000 futures_mid: 61552.45 , spot_mid: 61570.0 , basis: -17.54
current_timestamp: 1723161692500000000 futures_mid: 61593.05 , spot_mid: 61606.0 , basis: -12.96
current_timestamp: 1723161702500000000 futures_mid: 61587.45 , spot_mid: 61608.0 , basis: -20.54
current_timestamp: 1723161712500000000 futures_mid: 61561.15 , spot_mid: 61589.88 , basis: -28.73
current_timestamp: 1723161722500000000 futures_mid: 61589.95 , spot_mid: 61614.08 , basis: -24.14
current_timestamp: 1723161732500000000 futures_mid: 61608.95 , spot_mid: 61632.13 , basis: -23.18
current_timestamp: 1723161742500000000 futures_mid: 61653.45 , spot_mid: 61681.74 , basis: -28.29
current_timestamp: 1723161752500000000 futures_mid: 61673.45 , spot_mid: 61700.0 , basis: -26.54
current_timestamp: 1723161762500000000 futures_mid: 61663.95 , spot_mid: 61683.84 , basis: -19.89
current_timestamp: 1723161772500000000 futures_mid: 61640.85 , spot_mid: 61664.0 , basis: -23.15
current_timestamp: 1723161782500000000 futures_mid: 61634.15 , spot_mid: 61654.0 , basis: -19.85
current_timestamp: 1723161792500000000 futures_mid: 61618.05 , spot_mid: 61666.0 , basis: -47.94
current_timestamp: 1723161802500000000 futures_mid: 61626.65 , spot_mid: 61648.34 , basis: -21.69
current_timestamp: 1723161812500000000 futures_mid: 61586.25 , spot_mid: 61612.0 , basis: -25.74
current_timestamp: 1723161822500000000 futures_mid: 61624.65 , spot_mid: 61649.98 , basis: -25.33
current_timestamp: 1723161832500000000 futures_mid: 61611.55 , spot_mid: 61644.0 , basis: -32.46
current_timestamp: 1723161842500000000 futures_mid: 61633.95 , spot_mid: 61658.4 , basis: -24.46
current_timestamp: 1723161852500000000 futures_mid: 61635.95 , spot_mid: 61656.02 , basis: -20.07
current_timestamp: 1723161862500000000 futures_mid: 61671.45 , spot_mid: 61689.92 , basis: -18.47
current_timestamp: 1723161872500000000 futures_mid: 61651.55 , spot_mid: 61664.0 , basis: -12.46
current_timestamp: 1723161882500000000 futures_mid: 61614.15 , spot_mid: 61640.0 , basis: -25.84
current_timestamp: 1723161892500000000 futures_mid: 61605.95 , spot_mid: 61622.12 , basis: -16.18
current_timestamp: 1723161902500000000 futures_mid: 61583.95 , spot_mid: 61607.98 , basis: -24.04
import polars as pl
import holoviews as hv

df = pl.DataFrame(out).with_columns(
    pl.from_epoch('timestamp', time_unit='ns').alias('timestamp')
)

hv.extension('bokeh')

df.plot(x='timestamp')

Although this is a short-period sample, you can observe that the basis is mean-reverting. There may be statistical arbitrage opportunities, particularly if you are eligible for rebates or zero fees.

((df['mid_price'] - df['spot_mid_price']) / df['mid_price'] * 10000).alias('basis bp').plot(x='timestamp')
© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
Plain High-Frequency Grid Trading
High-Frequency Grid Trading with Skewing
Multiple Assets
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
MongoDB Atlas empowers you to build modern apps where you want, how you want, at the speed you want.
Ads by EthicalAds
Close Ad
 High-Frequency Grid TradingView page source
High-Frequency Grid Trading
Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.005% rebate, the highest market maker rebate available on Binance Futures. See Binance Upgrades USDⓢ-Margined Futures Liquidity Provider Program for more details.

Plain High-Frequency Grid Trading
This is a high-frequency version of Grid Trading that keeps posting orders on grids centered around the mid-price, maintaining a fixed interval and a set number of grids.

import numpy as np

from numba import njit, uint64, float64
from numba.typed import Dict

from hftbacktest import BUY, SELL, GTX, LIMIT

@njit
def gridtrading(hbt, recorder):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size
    grid_num = 20
    max_position = 5
    grid_interval = tick_size * 10
    half_spread = tick_size * 20

    # Running interval in nanoseconds.
    while hbt.elapse(100_000_000) == 0:
        # Clears cancelled, filled or expired orders.
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid = depth.best_bid
        best_ask = depth.best_ask

        mid_price = (best_bid + best_ask) / 2.0

        order_qty = 0.1 # np.round(notional_order_qty / mid_price / hbt.depth(asset_no).lot_size) * hbt.depth(asset_no).lot_size

        # Aligns the prices to the grid.
        bid_price = np.floor((mid_price - half_spread) / grid_interval) * grid_interval
        ask_price = np.ceil((mid_price + half_spread) / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if position < max_position and np.isfinite(bid_price): # position * mid_price < max_notional_position
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if position > -max_position and np.isfinite(ask_price): # position * mid_price > -max_notional_position
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return True
For generating order latency from the feed data file, which uses feed latency as order latency, please see Order Latency Data.

from hftbacktest import BacktestAsset, ROIVectorMarketDepthBacktest, Recorder

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20221003.npz',
            'data/ethusdt_20221004.npz',
            'data/ethusdt_20221005.npz',
            'data/ethusdt_20221006.npz',
            'data/ethusdt_20221007.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20221003.npz',
            'latency/feed_latency_20221004.npz',
            'latency/feed_latency_20221005.npz',
            'latency/feed_latency_20221006.npz',
            'latency/feed_latency_20221007.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
)
hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)
%%time
gridtrading(hbt, recorder.recorder)

_ = hbt.close()
CPU times: user 6min 5s, sys: 9.08 s, total: 6min 15s
Wall time: 6min 16s
from hftbacktest.stats import LinearAssetRecord

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=10_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-07 23:59:50	18.265693	25.144025	0.082691	0.021906	9489.819672	127.266294	3.774836	0.00013	9140.288
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_7_0.png
High-Frequency Grid Trading with Skewing
By incorporating position-based skewing, the strategy’s risk-adjusted returns can be improved.

@njit
def gridtrading(hbt, recorder, skew):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size
    grid_num = 20
    max_position = 5
    grid_interval = tick_size * 10
    half_spread = tick_size * 20

    # Running interval in nanoseconds.
    while hbt.elapse(100_000_000) == 0:
        # Clears cancelled, filled or expired orders.
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid = depth.best_bid
        best_ask = depth.best_ask

        mid_price = (best_bid + best_ask) / 2.0

        order_qty = 0.1 # np.round(notional_order_qty / mid_price / hbt.depth(asset_no).lot_size) * hbt.depth(asset_no).lot_size

        # The personalized price that considers skewing based on inventory risk is introduced,
        # which is described in the well-known Stokov-Avalleneda market-making paper.
        # https://math.nyu.edu/~avellane/HighFrequencyTrading.pdf
        reservation_price = mid_price - skew * tick_size * position

        # Since our price is skewed, it may cross the spread. To ensure market making and avoid crossing the spread,
        # limit the price to the best bid and best ask.
        bid_price = np.minimum(reservation_price - half_spread, best_bid)
        ask_price = np.maximum(reservation_price + half_spread, best_ask)

        # Aligns the prices to the grid.
        bid_price = np.floor(bid_price / grid_interval) * grid_interval
        ask_price = np.ceil(ask_price / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if position < max_position and np.isfinite(bid_price): # position * mid_price < max_notional_position
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if position > -max_position and np.isfinite(ask_price): # position * mid_price > -max_notional_position
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return True
Weak skew
hbt = ROIVectorMarketDepthBacktest([asset])

skew = 1

recorder = Recorder(1, 5_000_000)

gridtrading(hbt, recorder.recorder, skew)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=10_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-07 23:59:50	18.363916	25.321583	0.060482	0.014831	10563.644529	141.707178	4.077966	0.000085	9409.12
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_12_0.png
Strong skew
Under strong skew, the position is more limited compared to the weak skew case. You may also observe a spike in equity when the market moves sharply. However, in reality, this might not be realized due to order latency. Later, we will explore the impact of order latency and highlight the importance of using actual historical order latency data.

hbt = ROIVectorMarketDepthBacktest([asset])

skew = 10

recorder = Recorder(1, 5_000_000)

gridtrading(hbt, recorder.recorder, skew)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=10_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2022-10-03 00:00:00	2022-10-07 23:59:50	27.282302	47.25453	0.042574	0.005391	11838.874048	158.842253	7.897853	0.000054	8270.01
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_15_0.png
Multiple Assets
You might need to find the proper parameters for each asset to achieve better performance. As an example, here it uses single parameters set to demonstrate how the performance of a combination of multiple assets will be.

@njit
def gridtrading(hbt, recorder, half_spread, grid_interval, skew, order_qty):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size
    grid_num = 20
    max_position = grid_num * order_qty

    # Running interval in nanoseconds.
    while hbt.elapse(100_000_000) == 0:
        # Clears cancelled, filled or expired orders.
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid = depth.best_bid
        best_ask = depth.best_ask

        mid_price = (best_bid + best_ask) / 2.0

        normalized_position = position / order_qty

        # The personalized price that considers skewing based on inventory risk is introduced,
        # which is described in the well-known Stokov-Avalleneda market-making paper.
        # https://math.nyu.edu/~avellane/HighFrequencyTrading.pdf
        reservation_price = mid_price - skew * normalized_position

        # Since our price is skewed, it may cross the spread. To ensure market making and avoid crossing the spread,
        # limit the price to the best bid and best ask.
        bid_price = np.minimum(reservation_price - half_spread, best_bid)
        ask_price = np.maximum(reservation_price + half_spread, best_ask)

        # Ensures the grid interval aligns with the tick size, with the minimum set to the tick size.
        grid_interval = max(np.round(grid_interval / tick_size) * tick_size, tick_size)

        # Aligns the prices to the grid.
        bid_price = np.floor(bid_price / grid_interval) * grid_interval
        ask_price = np.ceil(ask_price / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if position < max_position and np.isfinite(bid_price): # position * mid_price < max_notional_position
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if position > -max_position and np.isfinite(ask_price): # position * mid_price > -max_notional_position
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return True
from hftbacktest import BUY_EVENT, SELL_EVENT

latency_data = np.concatenate(
    [np.load('latency/live_latency_{}.npz'.format(date))['data'] for date in range(20230701, 20230732)]
)

def backtest(args):
    asset_name, asset_info = args

    # Obtains the mid-price of the assset to determine the order quantity.
    snapshot = np.load('data/{}_20230630_eod.npz'.format(asset_name))['data']
    best_bid = max(snapshot[snapshot['ev'] & BUY_EVENT == BUY_EVENT]['px'])
    best_ask = min(snapshot[snapshot['ev'] & SELL_EVENT == SELL_EVENT]['px'])
    mid_price = (best_bid + best_ask) / 2.0

    asset = (
        BacktestAsset()
            .data(['data/{}_{}.npz'.format(asset_name, date) for date in range(20230701, 20230732)])
            .initial_snapshot('data/{}_20230630_eod.npz'.format(asset_name))
            .linear_asset(1.0)
            .intp_order_latency(latency_data)
            .log_prob_queue_model2()
            .no_partial_fill_exchange()
            .trading_value_fee_model(-0.00005, 0.0007)
            .tick_size(asset_info['tick_size'])
            .lot_size(asset_info['lot_size'])
            .roi_lb(0)
            .roi_ub(mid_price * 5)
    )
    hbt = ROIVectorMarketDepthBacktest([asset])

    # Sets the order quantity to be equivalent to a notional value of $100.
    order_qty = max(round((100 / mid_price) / asset_info['lot_size']), 1) * asset_info['lot_size']

    half_spread = mid_price * 0.0008
    grid_interval = mid_price * 0.0008
    skew = mid_price * 0.000025

    recorder = Recorder(1, 50_000_000)

    gridtrading(hbt, recorder.recorder, half_spread, grid_interval, skew, order_qty)

    hbt.close()

    recorder.to_npz('stats/gridtrading_{}.npz'.format(asset_name))
%%capture

import json
from multiprocessing import Pool

with open('assets.json', 'r') as f:
    assets =  json.load(f)

with Pool(16) as p:
    print(p.map(backtest, list(assets.items())))
import polars as pl
from hftbacktest.stats import LinearAssetRecord

equity_values = {}
for asset_name in assets.keys():
    data = np.load('stats/gridtrading_{}.npz'.format(asset_name))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )

    equity = stats.entire.with_columns(
        (pl.col('equity_wo_fee') - pl.col('fee')).alias('equity')
    ).select(['timestamp', 'equity'])
    equity_values[asset_name] = equity
from matplotlib import pyplot as plt

fig = plt.figure()
fig.set_size_inches(10, 3)

legend = []
net_equity = None
for i, equity in enumerate(list(equity_values.values())):
    asset_number = i + 1
    if net_equity is None:
        net_equity = equity['equity'].clone()
    else:
        net_equity += equity['equity'].clone()

    if asset_number % 10 == 0:
        # 2_000 is capital for each trading asset.
        net_equity_df = pl.DataFrame({
            'cum_ret': (net_equity / asset_number) / 2_000 * 100,
            'timestamp': equity['timestamp']
        })
        net_equity_rs_df = net_equity_df.group_by_dynamic(
            index_column='timestamp',
            every='1d'
        ).agg([
            pl.col('cum_ret').last()
        ])
        pnl = net_equity_rs_df['cum_ret'].diff()
        sr = pnl.mean() / pnl.std()
        ann_sr = sr * np.sqrt(365)

        plt.plot(net_equity_df['timestamp'], net_equity_df['cum_ret'])
        legend.append('{} assets, SR={:.2f} (Daily SR={:.2f})'.format(asset_number, ann_sr, sr))

plt.legend(
    legend,
    loc='upper center', bbox_to_anchor=(0.5, -0.15),
    fancybox=True, shadow=True, ncol=3
)

plt.grid()
plt.ylabel('Cumulative Returns (%)')
Text(0, 0.5, 'Cumulative Returns (%)')
../_images/tutorials_High-Frequency_Grid_Trading_21_1.png
© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
Binance Futures
Bybit
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
MongoDB Atlas empowers you to build modern apps where you want, how you want, at the speed you want.
Ads by EthicalAds
Close Ad
 High-Frequency Grid Trading - Comparison Across Other ExchangesView page source
High-Frequency Grid Trading - Comparison Across Other Exchanges
So far, we have explored examples in Binance Futures. In this section, we demonstrate how results can vary for the same pair and parameter set across different exchanges, due to differences in order flow.

Since each exchange may have its own distinct order flow, performance can differ significantly. This also highlights the need to explore alternative parameter sets to optimize performance for each specific exchange. By doing so, you can extend your analysis to other platforms such as OKX, Hyperliquid, and more.

import json
import datetime
import itertools

from multiprocessing import Pool

import polars as pl

import numpy as np

from numba import njit, uint64, float64
from numba.typed import Dict

from matplotlib import pyplot as plt

from hftbacktest import BUY, SELL, GTX, LIMIT, BUY_EVENT, SELL_EVENT
from hftbacktest import BacktestAsset, ROIVectorMarketDepthBacktest, Recorder
from hftbacktest.stats import LinearAssetRecord

@njit
def gridtrading(hbt, recorder, relative_half_spread, relative_grid_interval, min_grid_step, grid_num, skew, order_qty):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size
    max_position = grid_num * order_qty

    # Running interval in nanoseconds.
    while hbt.elapse(100_000_000) == 0:
        # Clears cancelled, filled or expired orders.
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid = depth.best_bid
        best_ask = depth.best_ask

        mid_price = (best_bid + best_ask) / 2.0

        normalized_position = position / order_qty

        relative_bid_depth = relative_half_spread + skew * normalized_position
        relative_ask_depth = relative_half_spread - skew * normalized_position

        # Please see Market Making with Alpha example series.
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Order%20Book%20Imbalance.html
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Basis.html
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20APT.html
        #
        # Without alpha, this relies heavily on rebates combined with short-term mean reversion to the current price —
        # a behavior that has been observed to be particularly strong in altcoins.
        alpha = 0.0
        forecast_mid_price = mid_price + alpha

        # Since our price is skewed, it may cross the spread. To ensure market making and avoid crossing the spread,
        # limit the price to the best bid and best ask.
        bid_price = np.minimum(forecast_mid_price * (1.0 - relative_bid_depth), best_bid)
        ask_price = np.maximum(forecast_mid_price * (1.0 + relative_ask_depth), best_ask)

        # min_grid_step enforces grid interval changes to be no less than min_grid_step, which
        # stabilizes the grid_interval and keeps the orders on the grid more stable.
        grid_interval = max(np.round(forecast_mid_price * relative_grid_interval / min_grid_step) * min_grid_step, min_grid_step)

        # Aligns the prices to the grid.
        bid_price = np.floor(bid_price / grid_interval) * grid_interval
        ask_price = np.ceil(ask_price / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if position < max_position and np.isfinite(bid_price): # position * mid_price < max_notional_position
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if position > -max_position and np.isfinite(ask_price): # position * mid_price > -max_notional_position
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        # Records the current state for stat calculation.
        recorder.record(hbt)
    return True
Binance Futures
Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.005% rebate, the highest market maker rebate available on Binance Futures. See Binance Upgrades USDⓢ-Margined Futures Liquidity Provider Program for more details.

dates = []
date = datetime.datetime(2025, 4, 1)
until = datetime.datetime(2025, 5, 19)
while date <= until:
    dates.append(date.strftime("%Y%m%d"))
    date += datetime.timedelta(days=1)

latency_data = np.concatenate(
    [np.load('binance_latency/order_latency_{}.npz'.format(date))['data'] for date in dates]
)

def backtest(args):
    asset_name, asset_info, half_spread = args

    # Obtains the mid-price of the assset to determine the order quantity.
    snapshot = np.load('binance_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))['data']
    best_bid = max(snapshot[snapshot['ev'] & BUY_EVENT == BUY_EVENT]['px'])
    best_ask = min(snapshot[snapshot['ev'] & SELL_EVENT == SELL_EVENT]['px'])
    mid_price = (best_bid + best_ask) / 2.0

    data = ['binance_data/{}/{}_{}.npz'.format(asset_name, asset_name, date) for date in dates]

    asset = (
        BacktestAsset()
            .data(data)
            .initial_snapshot('binance_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))
            .linear_asset(1.0)
            .intp_order_latency(latency_data)
            .power_prob_queue_model3(3.0)
            .no_partial_fill_exchange()
            .trading_value_fee_model(-0.00005, 0.0007)
            .tick_size(asset_info['tick_size'])
            .lot_size(asset_info['lot_size'])
            .roi_lb(0)
            .roi_ub(mid_price * 5)
    )
    hbt = ROIVectorMarketDepthBacktest([asset])

    # Sets the order quantity to be equivalent to a notional value of $100.
    order_qty = max(round((100 / mid_price) / asset_info['lot_size']), 1) * asset_info['lot_size']

    grid_num = 20
    grid_interval = half_spread
    skew = half_spread / grid_num
    min_grid_step = asset_info['tick_size']

    recorder = Recorder(1, 50_000_000)

    gridtrading(hbt, recorder.recorder, half_spread, grid_interval, min_grid_step, grid_num, skew, order_qty)

    hbt.close()

    recorder.to_npz('binance_stats/gridtrading_{}_{}.npz'.format(asset_name, half_spread))
%%capture

with open('binance_assets.json', 'r') as f:
    assets =  json.load(f)

args = list(itertools.product(list(assets.items()), [0.0005, 0.0010, 0.0015]))
args = [(*tup, x) for tup, x in args]

with Pool(16) as p:
    print(p.map(backtest, args))
As we have demonstrated so far, the strategy collectively produces a favorable equity curve when factoring in rebates.

equity_values = {}
half_spread = 0.001
for asset_name, _ in assets.items():
    data = np.load('binance_stats/gridtrading_{}_{}.npz'.format(asset_name, half_spread))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )

    equity = stats.entire.with_columns(
        (pl.col('equity_wo_fee') - pl.col('fee')).alias('equity')
    ).select(['timestamp', 'equity'])
    equity_values[asset_name] = equity
fig = plt.figure()
fig.set_size_inches(10, 3)

legend = []
net_equity = None
for i, equity in enumerate(list(equity_values.values())):
    asset_number = i + 1
    if net_equity is None:
        net_equity = equity['equity'].clone()
    else:
        net_equity += equity['equity'].clone()

# 2_000 is capital for each trading asset.
net_equity_df = pl.DataFrame({
    'cum_ret': (net_equity / asset_number) / 2_000 * 100,
    'timestamp': equity['timestamp']
})
net_equity_rs_df = net_equity_df.group_by_dynamic(
    index_column='timestamp',
    every='1d'
).agg([
    pl.col('cum_ret').last()
])
pnl = net_equity_rs_df['cum_ret'].diff()
sr = pnl.mean() / pnl.std()
ann_sr = sr * np.sqrt(365)

plt.plot(net_equity_df['timestamp'], net_equity_df['cum_ret'])
legend.append('{} assets, SR={:.2f} (Daily SR={:.2f})'.format(asset_number, ann_sr, sr))

plt.legend(
    legend,
    loc='upper center', bbox_to_anchor=(0.5, -0.15),
    fancybox=True, shadow=True, ncol=3
)

plt.grid()
plt.ylabel('Cumulative Returns (%)')
Text(0, 0.5, 'Cumulative Returns (%)')
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_7_1.png
In addition, this is for demonstration purpose to use the single parameter set, but you can find more optimum parameter set for each pair, which also have a risk to lead to the overfitting.

for half_spread in [0.0005, 0.001, 0.0015]:
    data = np.load('binance_stats/gridtrading_SUIUSDT_{}.npz'.format(half_spread))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )
    stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_9_0.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_9_1.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_9_2.png
for half_spread in [0.0005, 0.001, 0.0015]:
    data = np.load('binance_stats/gridtrading_ADAUSDT_{}.npz'.format(half_spread))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )
    stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_10_0.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_10_1.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_10_2.png
Bybit
Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.0025% rebate, the market maker rebate available on Bybit Futures. See Introduction to the Market Maker Incentive Program for more details.

latency_data = np.concatenate(
    [np.load('bybit_latency/order_latency_{}.npz'.format(date))['data'] for date in dates]
)

def backtest(args):
    asset_name, asset_info, half_spread = args

    # Obtains the mid-price of the assset to determine the order quantity.
    snapshot = np.load('bybit_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))['data']
    best_bid = max(snapshot[snapshot['ev'] & BUY_EVENT == BUY_EVENT]['px'])
    best_ask = min(snapshot[snapshot['ev'] & SELL_EVENT == SELL_EVENT]['px'])
    mid_price = (best_bid + best_ask) / 2.0

    data = ['bybit_data/{}/{}_{}.npz'.format(asset_name, asset_name, date) for date in dates]

    asset = (
        BacktestAsset()
            .data(data)
            # Tardis collects Bybit data from Tokyo, but the Bybit server is located in Singapore.
            #
            # Therefore, if we assume our strategy will run in Singapore, we need to adjust for the feed latency.
            # The round-trip time (RTT) between Tokyo and Singapore is approximately 70 ms.
            # For our purposes, we subtract 30 ms as the estimated one-way latency from Singapore to Tokyo, including a small buffer.
            #
            # https://docs.tardis.dev/historical-data-details/bybit#market-data-collection-details
            # https://bybit-exchange.github.io/docs/faq#where-are-bybits-servers-located
            # https://elitwilliams.medium.com/geographic-latency-in-crypto-how-to-optimally-co-locate-your-aws-trading-server-to-any-exchange-58965ea173a8
            .latency_offset(-30_000_000)
            .initial_snapshot('bybit_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))
            .linear_asset(1.0)
            .intp_order_latency(latency_data)
            .power_prob_queue_model3(3.0)
            .no_partial_fill_exchange()
            .trading_value_fee_model(-0.000025, 0.00055)
            .tick_size(asset_info['tick_size'])
            .lot_size(asset_info['lot_size'])
            .roi_lb(0)
            .roi_ub(mid_price * 5)
    )
    hbt = ROIVectorMarketDepthBacktest([asset])

    # Sets the order quantity to be equivalent to a notional value of $100.
    order_qty = max(round((100 / mid_price) / asset_info['lot_size']), 1) * asset_info['lot_size']

    grid_num = 20
    grid_interval = half_spread
    skew = half_spread / grid_num
    min_grid_step = asset_info['tick_size']

    recorder = Recorder(1, 50_000_000)

    gridtrading(hbt, recorder.recorder, half_spread, grid_interval, min_grid_step, grid_num, skew, order_qty)

    hbt.close()

    recorder.to_npz('bybit_stats/gridtrading_{}_{}.npz'.format(asset_name, half_spread))
%%capture

with open('bybit_assets.json', 'r') as f:
    assets =  json.load(f)

args = list(itertools.product(list(assets.items()), [0.0005, 0.0010, 0.0015]))
args = [(*tup, x) for tup, x in args]

with Pool(16) as p:
    print(p.map(backtest, args))
equity_values = {}
half_spread = 0.001
for asset_name, _ in assets.items():
    data = np.load('bybit_stats/gridtrading_{}_{}.npz'.format(asset_name, half_spread))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )

    equity = stats.entire.with_columns(
        (pl.col('equity_wo_fee') - pl.col('fee')).alias('equity')
    ).select(['timestamp', 'equity'])
    equity_values[asset_name] = equity
fig = plt.figure()
fig.set_size_inches(10, 3)

legend = []
net_equity = None
for i, equity in enumerate(list(equity_values.values())):
    asset_number = i + 1
    if net_equity is None:
        net_equity = equity['equity'].clone()
    else:
        net_equity += equity['equity'].clone()

# 2_000 is capital for each trading asset.
net_equity_df = pl.DataFrame({
    'cum_ret': (net_equity / asset_number) / 2_000 * 100,
    'timestamp': equity['timestamp']
})
net_equity_rs_df = net_equity_df.group_by_dynamic(
    index_column='timestamp',
    every='1d'
).agg([
    pl.col('cum_ret').last()
])
pnl = net_equity_rs_df['cum_ret'].diff()
sr = pnl.mean() / pnl.std()
ann_sr = sr * np.sqrt(365)

plt.plot(net_equity_df['timestamp'], net_equity_df['cum_ret'])
legend.append('{} assets, SR={:.2f} (Daily SR={:.2f})'.format(asset_number, ann_sr, sr))

plt.legend(
    legend,
    loc='upper center', bbox_to_anchor=(0.5, -0.15),
    fancybox=True, shadow=True, ncol=3
)

plt.grid()
plt.ylabel('Cumulative Returns (%)')
Text(0, 0.5, 'Cumulative Returns (%)')
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_15_1.png
You can observe performance differences across exchanges using the same parameter set.

for half_spread in [0.0005, 0.001, 0.0015]:
    data = np.load('bybit_stats/gridtrading_SUIUSDT_{}.npz'.format(half_spread))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )
    stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_17_0.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_17_1.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_17_2.png
for half_spread in [0.0005, 0.001, 0.0015]:
    data = np.load('bybit_stats/gridtrading_ADAUSDT_{}.npz'.format(half_spread))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )
    stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_18_0.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_18_1.png
../_images/tutorials_High-Frequency_Grid_Trading_-_Comparison_Across_Other_Exchanges_18_2.png
Regarding applying the same parameter set to the multiple pairs in generalized way, you need more generalized model about the volatility and the order flow such like you’ve seen in the GLFT example. Also, you can see volatility regime change over time-horizon affecting the performance in April in the plot. We will provide the example another emprical approach other than the GLFT example, as a simplified version using non-parametric approach.

© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Binance
Bybit
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Develop and launch modern apps with MongoDB Atlas, a resilient data platform.
Ads by EthicalAds
Close Ad
 High-Frequency Grid Trading - Simplified from GLFTView page source
High-Frequency Grid Trading - Simplified from GLFT
One of the challenges in using the GLFT model is that it assumes a parametric form for order arrival intensity. However, in some cases, the data does not fit this function well. To address this, you can replace the parametric model with non-parametric approaches, such as using a simple mean, median, or a percentile estimate. A simpler solution is to remove the dynamic estimation of spread and skew based on order arrival intensity, relying only on volatility.

This issue is more common in pairs with a large tick size. As demonstrated in the large tick size assets example, the problem can be mitigated by incorporating the micro price. While the BBO-based micro price has little impact on pairs with small tick sizes, it can be highly effective for large tick size pairs.

import json
import datetime
import itertools

from multiprocessing import Pool

import polars as pl

import numpy as np

from numba import njit, uint64, float64
from numba.typed import Dict

from matplotlib import pyplot as plt

from hftbacktest import BUY, SELL, GTX, LIMIT, BUY_EVENT, SELL_EVENT
from hftbacktest import BacktestAsset, ROIVectorMarketDepthBacktest, Recorder
from hftbacktest.stats import LinearAssetRecord

@njit
def gridtrading(hbt, recorder, vol_to_half_spread, min_grid_step, grid_num, skew, max_notional_position):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size
    lot_size = hbt.depth(asset_no).lot_size

    mid_price_chg = np.full(300_000_000, np.nan, np.float64)

    t = 0
    prev_mid_price_tick = np.nan
    mid_price_tick = np.nan
    volatility = np.nan

    # Running interval in nanoseconds.
    while hbt.elapse(100_000_000) == 0:
        # Clears cancelled, filled or expired orders.
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid = depth.best_bid
        best_ask = depth.best_ask
        best_bid_qty = depth.best_bid_qty
        best_ask_qty = depth.best_ask_qty

        micro_price = (best_bid * best_ask_qty + best_ask * best_bid_qty) / (best_bid_qty + best_ask_qty)
        mid_price = (best_bid + best_ask) / 2.0

        mid_price_tick = mid_price / tick_size

        # Records the mid-price change for volatility calculation.
        mid_price_chg[t] = mid_price_tick - prev_mid_price_tick
        prev_mid_price_tick = mid_price_tick

        #--------------------------------------------------------
        # Calculates the market volatility.

        # Updates the volatility every 5-sec.
        if t % 50 == 0:
            # Window size is 10-minute.
            if t >= 6_000 - 1:
                # Updates the volatility.
                volatility = np.nanstd(mid_price_chg[t + 1 - 6_000:t + 1]) * np.sqrt(10)

        notional_position = position * mid_price
        normalized_position = notional_position / max_notional_position

        half_spread_tick = volatility * vol_to_half_spread

        bid_depth_tick = half_spread_tick * (1 + skew * normalized_position)
        ask_depth_tick = half_spread_tick * (1 - skew * normalized_position)

        # Please see Market Making with Alpha example series.
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Order%20Book%20Imbalance.html
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20Basis.html
        # https://hftbacktest.readthedocs.io/en/latest/tutorials/Market%20Making%20with%20Alpha%20-%20APT.html
        #
        # Without alpha, this relies heavily on rebates combined with short-term mean reversion to the current price —
        # a behavior that has been observed to be particularly strong in altcoins.
        forecast_mid_price = micro_price # mid_price + b1 * alpha

        # Sets the order quantity to be equivalent to a notional value of $100.
        order_qty = max(round((100 / mid_price) / lot_size), 1) * lot_size

        # Since our price is skewed, it may cross the spread. To ensure market making and avoid crossing the spread,
        # limit the price to the best bid and best ask.
        bid_price = np.minimum(forecast_mid_price - bid_depth_tick * tick_size, best_bid)
        ask_price = np.maximum(forecast_mid_price + ask_depth_tick * tick_size, best_ask)

        # min_grid_step enforces grid interval changes to be no less than min_grid_step, which
        # stabilizes the grid_interval and keeps the orders on the grid more stable.
        grid_interval = max(np.round(half_spread_tick * tick_size / min_grid_step) * min_grid_step, min_grid_step)

        # Aligns the prices to the grid.
        bid_price = np.floor(bid_price / grid_interval) * grid_interval
        ask_price = np.ceil(ask_price / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if normalized_position < 1 and np.isfinite(bid_price):
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if normalized_position > -1 and np.isfinite(ask_price):
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        #--------------------------------------------------------
        # Records variables and stats for analysis.

        t += 1

        if t >= len(mid_price_chg):
            raise Exception

        # Records the current state for stat calculation.
        recorder.record(hbt)
Binance
Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.005% rebate, the highest market maker rebate available on Binance Futures. See Binance Upgrades USDⓢ-Margined Futures Liquidity Provider Program for more details.

dates = []
date = datetime.datetime(2025, 4, 1)
until = datetime.datetime(2025, 7, 31)
while date <= until:
    dates.append(date.strftime("%Y%m%d"))
    date += datetime.timedelta(days=1)
latency_data = np.concatenate(
    [np.load('latency/order_latency_{}.npz'.format(date))['data'] for date in dates]
)

def backtest(args):
    asset_name, asset_info, vol_to_half_spread = args

    # Obtains the mid-price of the assset to determine the range of interest for the market depth.
    snapshot = np.load('binance_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))['data']
    best_bid = max(snapshot[snapshot['ev'] & BUY_EVENT == BUY_EVENT]['px'])
    best_ask = min(snapshot[snapshot['ev'] & SELL_EVENT == SELL_EVENT]['px'])
    mid_price = (best_bid + best_ask) / 2.0

    data = ['binance_data/{}/{}_{}.npz'.format(asset_name, asset_name, date) for date in dates]

    asset = (
        BacktestAsset()
            .data(data)
            .initial_snapshot('binance_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))
            .linear_asset(1.0)
            .intp_order_latency(latency_data)
            .power_prob_queue_model3(3.0)
            .no_partial_fill_exchange()
            .trading_value_fee_model(-0.00005, 0.0007)
            .tick_size(asset_info['tick_size'])
            .lot_size(asset_info['lot_size'])
            .roi_lb(0)
            .roi_ub(mid_price * 10)
    )
    hbt = ROIVectorMarketDepthBacktest([asset])

    max_notional_position = 1000
    grid_num = 20
    skew = 1
    min_grid_step = asset_info['tick_size']

    recorder = Recorder(1, 300_000_000)

    gridtrading(hbt, recorder.recorder, vol_to_half_spread, min_grid_step, grid_num, skew, max_notional_position)

    hbt.close()

    recorder.to_npz('gridtrading_stats/binance_{}_{}.npz'.format(asset_name, vol_to_half_spread))
%%capture

with open('binance_assets.json', 'r') as f:
    assets =  json.load(f)

args = list(itertools.product(list(assets.items()), [5]))
args = [(*tup, x) for tup, x in args]

with Pool(4) as p:
    print(p.map(backtest, args))
data = np.load('gridtrading_stats/binance_SOLUSDT_5.npz')['0']
stats = (
    LinearAssetRecord(data)
        .resample('5m')
        .stats()
)
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_6_0.png
data = np.load('gridtrading_stats/binance_ONDOUSDT_5.npz')['0']
stats = (
    LinearAssetRecord(data)
        .resample('5m')
        .stats()
)
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_7_0.png
data = np.load('gridtrading_stats/binance_XRPUSDT_5.npz')['0']
stats = (
    LinearAssetRecord(data)
        .resample('5m')
        .stats()
)
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_8_0.png
equity_values = {}
for i, (asset_name, _) in enumerate(assets.items()):
    data = np.load('gridtrading_stats/binance_{}_5.npz'.format(asset_name))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )

    equity = stats.entire.with_columns(
        (pl.col('equity_wo_fee') - pl.col('fee')).alias('equity')
    ).select(['timestamp', 'equity'])
    equity_values[asset_name] = equity
fig = plt.figure()
fig.set_size_inches(10, 3)

legend = []
net_equity = None
for i, equity in enumerate(list(equity_values.values())):
    asset_number = i + 1
    if net_equity is None:
        net_equity = equity['equity'].clone()
    else:
        net_equity += equity['equity'].clone()

# 2_000 is capital for each trading asset.
net_equity_df = pl.DataFrame({
    'cum_ret': (net_equity / asset_number) / 2_000 * 100,
    'timestamp': equity['timestamp']
})
net_equity_rs_df = net_equity_df.group_by_dynamic(
    index_column='timestamp',
    every='1d'
).agg([
    pl.col('cum_ret').last()
])
pnl = net_equity_rs_df['cum_ret'].diff()
sr = pnl.mean() / pnl.std()
ann_sr = sr * np.sqrt(365)

plt.plot(net_equity_df['timestamp'], net_equity_df['cum_ret'])
legend.append('{} assets, SR={:.2f} (Daily SR={:.2f})'.format(asset_number, ann_sr, sr))

plt.legend(
    legend,
    loc='upper center', bbox_to_anchor=(0.5, -0.15),
    fancybox=True, shadow=True, ncol=3
)

plt.grid()
plt.ylabel('Cumulative Returns (%)')
Text(0, 0.5, 'Cumulative Returns (%)')
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_10_1.png
Bybit
Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.0025% rebate, the market maker rebate available on Bybit Futures. See Introduction to the Market Maker Incentive Program for more details.

dates = []
date = datetime.datetime(2025, 4, 1)
until = datetime.datetime(2025, 7, 31)
while date <= until:
    dates.append(date.strftime("%Y%m%d"))
    date += datetime.timedelta(days=1)
latency_data = np.concatenate(
    [np.load('bybit_latency/order_latency_{}.npz'.format(date))['data'] for date in dates]
)

def backtest(args):
    asset_name, asset_info, vol_to_half_spread = args

    # Obtains the mid-price of the assset to determine the range of interest for the market depth.
    snapshot = np.load('bybit_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))['data']
    best_bid = max(snapshot[snapshot['ev'] & BUY_EVENT == BUY_EVENT]['px'])
    best_ask = min(snapshot[snapshot['ev'] & SELL_EVENT == SELL_EVENT]['px'])
    mid_price = (best_bid + best_ask) / 2.0

    data = ['bybit_data/{}/{}_{}.npz'.format(asset_name, asset_name, date) for date in dates]

    asset = (
        BacktestAsset()
            .data(data)
            # Tardis collects Bybit data from Tokyo, but the Bybit server is located in Singapore.
            #
            # Therefore, if we assume our strategy will run in Singapore, we need to adjust for the feed latency.
            # The round-trip time (RTT) between Tokyo and Singapore is approximately 70 ms.
            # For our purposes, we subtract 30 ms as the estimated one-way latency from Singapore to Tokyo, including a small buffer.
            #
            # https://docs.tardis.dev/historical-data-details/bybit#market-data-collection-details
            # https://bybit-exchange.github.io/docs/faq#where-are-bybits-servers-located
            # https://elitwilliams.medium.com/geographic-latency-in-crypto-how-to-optimally-co-locate-your-aws-trading-server-to-any-exchange-58965ea173a8
            .latency_offset(-30_000_000)
            .initial_snapshot('bybit_data/{}/{}_20250331_eod.npz'.format(asset_name, asset_name))
            .linear_asset(1.0)
            .intp_order_latency(latency_data)
            .power_prob_queue_model3(3.0)
            .no_partial_fill_exchange()
            .trading_value_fee_model(-0.000025, 0.00055)
            .tick_size(asset_info['tick_size'])
            .lot_size(asset_info['lot_size'])
            .roi_lb(0)
            .roi_ub(mid_price * 10)
    )
    hbt = ROIVectorMarketDepthBacktest([asset])

    max_notional_position = 1000
    grid_num = 20
    skew = 1
    min_grid_step = asset_info['tick_size']

    recorder = Recorder(1, 300_000_000)

    gridtrading(hbt, recorder.recorder, vol_to_half_spread, min_grid_step, grid_num, skew, max_notional_position)

    hbt.close()

    recorder.to_npz('gridtrading_stats/bybit_{}_{}.npz'.format(asset_name, vol_to_half_spread))
%%capture

with open('bybit_assets.json', 'r') as f:
    assets =  json.load(f)

args = list(itertools.product(list(assets.items()), [5]))
args = [(*tup, x) for tup, x in args]

with Pool(4) as p:
    print(p.map(backtest, args))
data = np.load('gridtrading_stats/bybit_SOLUSDT_5.npz')['0']
stats = (
    LinearAssetRecord(data)
        .resample('5m')
        .stats()
)
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_15_0.png
data = np.load('gridtrading_stats/bybit_ONDOUSDT_5.npz')['0']
stats = (
    LinearAssetRecord(data)
        .resample('5m')
        .stats()
)
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_16_0.png
data = np.load('gridtrading_stats/bybit_XRPUSDT_5.npz')['0']
stats = (
    LinearAssetRecord(data)
        .resample('5m')
        .stats()
)
stats.plot()
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_17_0.png
equity_values = {}
for i, (asset_name, _) in enumerate(assets.items()):
    data = np.load('gridtrading_stats/bybit_{}_5.npz'.format(asset_name))['0']
    stats = (
        LinearAssetRecord(data)
            .resample('5m')
            .stats()
    )

    equity = stats.entire.with_columns(
        (pl.col('equity_wo_fee') - pl.col('fee')).alias('equity')
    ).select(['timestamp', 'equity'])
    equity_values[asset_name] = equity
fig = plt.figure()
fig.set_size_inches(10, 3)

legend = []
net_equity = None
for i, equity in enumerate(list(equity_values.values())):
    asset_number = i + 1
    if net_equity is None:
        net_equity = equity['equity'].clone()
    else:
        net_equity += equity['equity'].clone()

# 2_000 is capital for each trading asset.
net_equity_df = pl.DataFrame({
    'cum_ret': (net_equity / asset_number) / 2_000 * 100,
    'timestamp': equity['timestamp']
})
net_equity_rs_df = net_equity_df.group_by_dynamic(
    index_column='timestamp',
    every='1d'
).agg([
    pl.col('cum_ret').last()
])
pnl = net_equity_rs_df['cum_ret'].diff()
sr = pnl.mean() / pnl.std()
ann_sr = sr * np.sqrt(365)

plt.plot(net_equity_df['timestamp'], net_equity_df['cum_ret'])
legend.append('{} assets, SR={:.2f} (Daily SR={:.2f})'.format(asset_number, ann_sr, sr))

plt.legend(
    legend,
    loc='upper center', bbox_to_anchor=(0.5, -0.15),
    fancybox=True, shadow=True, ncol=3
)

plt.grid()
plt.ylabel('Cumulative Returns (%)')
Text(0, 0.5, 'Cumulative Returns (%)')
../_images/tutorials_High-Frequency_Grid_Trading_-_Simplified_from_GLFT_19_1.png
© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency from Feed Latency
Live Order Latency
Order Latency from Amplified Feed Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Develop and launch modern apps with MongoDB Atlas, a resilient data platform.
Ads by EthicalAds
Close Ad
 Impact of Order LatencyView page source
Impact of Order Latency
This example illustrates the impact of order latency on the performance of the strategy.

Note: This example is for educational purposes only and demonstrates effective strategies for high-frequency market-making schemes. All backtests are based on a 0.005% rebate, the highest market maker rebate available on Binance Futures. See Binance Upgrades USDⓢ-Margined Futures Liquidity Provider Program for more details.

import numpy as np

from numba import njit, uint64
from numba.typed import Dict

from hftbacktest import (
    BacktestAsset,
    ROIVectorMarketDepthBacktest,
    GTX,
    LIMIT,
    BUY,
    SELL,
    BUY_EVENT,
    Recorder
)
from hftbacktest.stats import LinearAssetRecord


@njit
def measure_trading_intensity(order_arrival_depth, out):
    max_tick = 0
    for depth in order_arrival_depth:
        if not np.isfinite(depth):
            continue

        # Sets the tick index to 0 for the nearest possible best price
        # as the order arrival depth in ticks is measured from the mid-price
        tick = round(depth / .5) - 1

        # In a fast-moving market, buy trades can occur below the mid-price (and vice versa for sell trades)
        # since the mid-price is measured in a previous time-step;
        # however, to simplify the problem, we will exclude those cases.
        if tick < 0 or tick >= len(out):
            continue

        # All of our possible quotes within the order arrival depth,
        # excluding those at the same price, are considered executed.
        out[:tick] += 1

        max_tick = max(max_tick, tick)
    return out[:max_tick]

@njit
def linear_regression(x, y):
    sx = np.sum(x)
    sy = np.sum(y)
    sx2 = np.sum(x ** 2)
    sxy = np.sum(x * y)
    w = len(x)
    slope = (w * sxy - sx * sy) / (w * sx2 - sx**2)
    intercept = (sy - slope * sx) / w
    return slope, intercept

@njit
def compute_coeff(xi, gamma, delta, A, k):
    inv_k = np.divide(1, k)
    c1 = 1 / (xi * delta) * np.log(1 + xi * delta * inv_k)
    c2 = np.sqrt(np.divide(gamma, 2 * A * delta * k) * ((1 + xi * delta * inv_k) ** (k / (xi * delta) + 1)))
    return c1, c2

@njit
def gridtrading_glft_mm(hbt, order_qty, recorder):
    asset_no = 0
    tick_size = hbt.depth(asset_no).tick_size

    arrival_depth = np.full(10_000_000, np.nan, np.float64)
    mid_price_chg = np.full(10_000_000, np.nan, np.float64)

    t = 0
    prev_mid_price_tick = np.nan
    mid_price_tick = np.nan

    tmp = np.zeros(500, np.float64)
    ticks = np.arange(len(tmp)) + 0.5

    A = np.nan
    k = np.nan
    volatility = np.nan
    gamma = 0.05
    delta = 1
    adj1 = 1

    # adj2 is determined according to the order quantity.
    grid_num = 20
    max_position = grid_num * order_qty
    adj2 = 1 / max_position

    # Checks every 100 milliseconds.
    while hbt.elapse(100_000_000) == 0:
        #--------------------------------------------------------
        # Records market order's arrival depth from the mid-price.
        if not np.isnan(mid_price_tick):
            depth = -np.inf
            for last_trade in hbt.last_trades(asset_no):
                trade_price_tick = last_trade.px / tick_size

                if last_trade.ev & BUY_EVENT == BUY_EVENT:
                    depth = max(trade_price_tick - mid_price_tick, depth)
                else:
                    depth = max(mid_price_tick - trade_price_tick, depth)
            arrival_depth[t] = depth

        hbt.clear_last_trades(asset_no)
        hbt.clear_inactive_orders(asset_no)

        depth = hbt.depth(asset_no)
        position = hbt.position(asset_no)
        orders = hbt.orders(asset_no)

        best_bid_tick = depth.best_bid_tick
        best_ask_tick = depth.best_ask_tick

        prev_mid_price_tick = mid_price_tick
        mid_price_tick = (best_bid_tick + best_ask_tick) / 2.0

        # Records the mid-price change for volatility calculation.
        mid_price_chg[t] = mid_price_tick - prev_mid_price_tick

        #--------------------------------------------------------
        # Calibrates A, k and calculates the market volatility.

        # Updates A, k, and the volatility every 5-sec.
        if t % 50 == 0:
            # Window size is 10-minute.
            if t >= 6_000 - 1:
                # Calibrates A, k
                tmp[:] = 0
                lambda_ = measure_trading_intensity(arrival_depth[t + 1 - 6_000:t + 1], tmp)
                if len(lambda_) > 2:
                    lambda_ = lambda_[:70] / 600
                    x = ticks[:len(lambda_)]
                    y = np.log(lambda_)
                    k_, logA = linear_regression(x, y)
                    A = np.exp(logA)
                    k = -k_

                # Updates the volatility.
                volatility = np.nanstd(mid_price_chg[t + 1 - 6_000:t + 1]) * np.sqrt(10)

        #--------------------------------------------------------
        # Computes bid price and ask price.

        c1, c2 = compute_coeff(gamma, gamma, delta, A, k)

        half_spread_tick = (c1 + delta / 2 * c2 * volatility) * adj1
        skew = c2 * volatility * adj2

        reservation_price_tick = mid_price_tick - skew * position

        bid_price_tick = min(np.round(reservation_price_tick - half_spread_tick), best_bid_tick)
        ask_price_tick = max(np.round(reservation_price_tick + half_spread_tick), best_ask_tick)

        bid_price = bid_price_tick * tick_size
        ask_price = ask_price_tick * tick_size

        grid_interval = max(np.round(half_spread_tick) * tick_size, tick_size)

        bid_price = np.floor(bid_price / grid_interval) * grid_interval
        ask_price = np.ceil(ask_price / grid_interval) * grid_interval

        #--------------------------------------------------------
        # Updates quotes.

        # Creates a new grid for buy orders.
        new_bid_orders = Dict.empty(np.uint64, np.float64)
        if position < max_position and np.isfinite(bid_price):
            for i in range(grid_num):
                bid_price_tick = round(bid_price / tick_size)

                # order price in tick is used as order id.
                new_bid_orders[uint64(bid_price_tick)] = bid_price

                bid_price -= grid_interval

        # Creates a new grid for sell orders.
        new_ask_orders = Dict.empty(np.uint64, np.float64)
        if position > -max_position and np.isfinite(ask_price):
            for i in range(grid_num):
                ask_price_tick = round(ask_price / tick_size)

                # order price in tick is used as order id.
                new_ask_orders[uint64(ask_price_tick)] = ask_price

                ask_price += grid_interval

        order_values = orders.values();
        while order_values.has_next():
            order = order_values.get()
            # Cancels if a working order is not in the new grid.
            if order.cancellable:
                if (
                    (order.side == BUY and order.order_id not in new_bid_orders)
                    or (order.side == SELL and order.order_id not in new_ask_orders)
                ):
                    hbt.cancel(asset_no, order.order_id, False)

        for order_id, order_price in new_bid_orders.items():
            # Posts a new buy order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_buy_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        for order_id, order_price in new_ask_orders.items():
            # Posts a new sell order if there is no working order at the price on the new grid.
            if order_id not in orders:
                hbt.submit_sell_order(asset_no, order_id, order_price, order_qty, GTX, LIMIT, False)

        #--------------------------------------------------------
        # Records variables and stats for analysis.

        t += 1

        if t >= len(arrival_depth) or t >= len(mid_price_chg):
            raise Exception

        # Records the current state for stat calculation.
        recorder.record(hbt)
Order Latency from Feed Latency
Please see the tutorial on generating artificial order latency data from feed latency.

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20230401.npz',
            'data/ethusdt_20230402.npz',
            'data/ethusdt_20230403.npz',
            'data/ethusdt_20230404.npz',
            'data/ethusdt_20230405.npz'
        ])
        .initial_snapshot('data/ethusdt_20230331_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/feed_latency_20230401.npz',
            'latency/feed_latency_20230402.npz',
            'latency/feed_latency_20230403.npz',
            'latency/feed_latency_20230404.npz',
            'latency/feed_latency_20230405.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

gridtrading_glft_mm(hbt, 1, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=25_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2023-04-01 00:00:00	2023-04-05 23:59:50	-0.197608	-0.224204	-0.001021	0.060794	4459.903239	328.415763	-0.016794	-6.2176e-7	75431.07
stats.plot()
../_images/tutorials_Impact_of_Order_Latency_4_0.png
Live Order Latency
latency_data = np.concatenate(
    [np.load('latency/live_order_latency_{}.npz'.format(date))['data'] for date in range(20230401, 20230406)]
)

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20230401.npz',
            'data/ethusdt_20230402.npz',
            'data/ethusdt_20230403.npz',
            'data/ethusdt_20230404.npz',
            'data/ethusdt_20230405.npz'
        ])
        .initial_snapshot('data/ethusdt_20230331_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency(latency_data)
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

gridtrading_glft_mm(hbt, 1, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=25_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2023-04-01 00:00:00	2023-04-05 23:59:50	1.536293	1.741565	0.007814	0.051916	4563.105627	336.150295	0.150518	0.000005	67694.55
stats.plot()
../_images/tutorials_Impact_of_Order_Latency_7_0.png
Order Latency from Amplified Feed Latency
Order entry latency is 4 times the feed latency and order response latency is 3 times the feed latency.

asset = (
    BacktestAsset()
        .data([
            'data/ethusdt_20230401.npz',
            'data/ethusdt_20230402.npz',
            'data/ethusdt_20230403.npz',
            'data/ethusdt_20230404.npz',
            'data/ethusdt_20230405.npz'
        ])
        .initial_snapshot('data/ethusdt_20221002_eod.npz')
        .linear_asset(1.0)
        .intp_order_latency([
            'latency/amp_feed_latency_20230401.npz',
            'latency/amp_feed_latency_20230402.npz',
            'latency/amp_feed_latency_20230403.npz',
            'latency/amp_feed_latency_20230404.npz',
            'latency/amp_feed_latency_20230405.npz'
        ])
        .power_prob_queue_model(2.0)
        .no_partial_fill_exchange()
        .trading_value_fee_model(-0.00005, 0.0007)
        .tick_size(0.01)
        .lot_size(0.001)
        .roi_lb(0.0)
        .roi_ub(3000.0)
        .last_trades_capacity(10000)
)

hbt = ROIVectorMarketDepthBacktest([asset])

recorder = Recorder(1, 5_000_000)

gridtrading_glft_mm(hbt, 1, recorder.recorder)

hbt.close()

stats = LinearAssetRecord(recorder.get(0)).stats(book_size=25_000)
stats.summary()
shape: (1, 11)
start	end	SR	Sortino	Return	MaxDrawdown	DailyNumberOfTrades	DailyTurnover	ReturnOverMDD	ReturnOverTrade	MaxPositionValue
datetime[μs]	datetime[μs]	f64	f64	f64	f64	f64	f64	f64	f64	f64
2023-04-01 00:00:00	2023-04-05 23:59:50	-0.376802	-0.430111	-0.002163	0.053785	4366.301072	321.501683	-0.040224	-0.000001	75711.93
stats.plot()
../_images/tutorials_Impact_of_Order_Latency_10_0.png
© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest

 hftbacktest
Search docs
Tutorials

Data Preparation
Getting Started
Working with Market Depth and Trades
Integrating Custom Data
Making Multiple Markets - Introduction
High-Frequency Grid Trading
High-Frequency Grid Trading - Comparison Across Other Exchanges
High-Frequency Grid Trading - Simplified from GLFT
Impact of Order Latency
Order Latency Data
Guéant–Lehalle–Fernandez-Tapia Market Making Model and Grid Trading
Making Multiple Markets
Probability Queue Position Models
Risk Mitigation through Price Protection in Extreme Market Conditions
Level-3 Backtesting
Market Making with Alpha - Order Book Imbalance
Market Making with Alpha - Basis
Market Making with Alpha - APT
Queue-Based Market Making in Large Tick Size Assets
Fusing Depth Data
Accelerated Backtesting
Research Pricing Framework
Examples
User Guide

Migration To v2
Data
Latency Models
Order Fill
JIT Compilation Overhead
Debugging Backtesting and Live Discrepancies
Market Maker Program
API Reference

Initialization
Backtester
Constants
Statistics
Data Validation
Data Utilities
Index
Copilot & Cursor letting you down? The AI Agent that gets your codebase Install Augment Now
Ads by EthicalAds
Close Ad
 Order Latency DataView page source
Order Latency Data
To obtain more realistic backtesting results, accounting for latencies is crucial. Therefore, it’s important to collect both feed data and order data with timestamps to measure your order latency. The best approach is to gather your own order latencies. You can collect order latency based on your live trading or by regularly submitting orders at a price that cannot be filled and then canceling them for recording purposes. However, if you don’t have access to them or want to establish a target, you will need to artificially generate order latency. You can model this latency based on factors such as feed latency, trade volume, and the number of events. In this guide, we will demonstrate a simple method to generate order latency from feed latency using a multiplier and offset for adjustment.

First, loads the feed data.

import numpy as np

data = np.load('btcusdt_20200201.npz')['data']
data
array([(3758096386, 1580515202342000000, 1580515202497052000, 9364.51, 1.197, 0, 0, 0.),
       (3758096386, 1580515202342000000, 1580515202497346000, 9365.67, 0.02 , 0, 0, 0.),
       (3758096386, 1580515202342000000, 1580515202497352000, 9365.86, 0.01 , 0, 0, 0.),
       ...,
       (3489660929, 1580601599836000000, 1580601599962961000, 9351.47, 3.914, 0, 0, 0.),
       (3489660929, 1580601599836000000, 1580601599963461000, 9397.78, 0.1  , 0, 0, 0.),
       (3489660929, 1580601599848000000, 1580601599973647000, 9348.14, 3.98 , 0, 0, 0.)],
      dtype=[('ev', '<i8'), ('exch_ts', '<i8'), ('local_ts', '<i8'), ('px', '<f8'), ('qty', '<f8'), ('order_id', '<u8'), ('ival', '<i8'), ('fval', '<f8')])
For easy manipulation, converts it into a DataFrame.

import polars as pl

df = pl.DataFrame(data)
df
shape: (27_532_602, 8)
ev	exch_ts	local_ts	px	qty	order_id	ival	fval
i64	i64	i64	f64	f64	u64	i64	f64
3758096386	1580515202342000000	1580515202497052000	9364.51	1.197	0	0	0.0
3758096386	1580515202342000000	1580515202497346000	9365.67	0.02	0	0	0.0
3758096386	1580515202342000000	1580515202497352000	9365.86	0.01	0	0	0.0
3758096386	1580515202342000000	1580515202497357000	9366.36	0.002	0	0	0.0
3758096386	1580515202342000000	1580515202497363000	9366.36	0.003	0	0	0.0
…	…	…	…	…	…	…	…
3489660929	1580601599812000000	1580601599944404000	9397.79	0.0	0	0	0.0
3489660929	1580601599826000000	1580601599952176000	9354.8	4.07	0	0	0.0
3489660929	1580601599836000000	1580601599962961000	9351.47	3.914	0	0	0.0
3489660929	1580601599836000000	1580601599963461000	9397.78	0.1	0	0	0.0
3489660929	1580601599848000000	1580601599973647000	9348.14	3.98	0	0	0.0
Selects only the events that have both a valid exchange timestamp and a valid local timestamp to get feed latency.

from hftbacktest import EXCH_EVENT, LOCAL_EVENT

df = df.filter((pl.col('ev') & EXCH_EVENT == EXCH_EVENT) & (pl.col('ev') & LOCAL_EVENT == LOCAL_EVENT))
Reduces the number of rows by resampling to approximately 1-second intervals.

df = df.with_columns(
    pl.col('local_ts').alias('ts')
).group_by_dynamic(
    'ts', every='1000000000i'
).agg(
    pl.col('exch_ts').last(),
    pl.col('local_ts').last()
).drop('ts')

df
shape: (86_394, 2)
exch_ts	local_ts
i64	i64
1580515202843000000	1580515202979365000
1580515203551000000	1580515203943566000
1580515203789000000	1580515204875639000
1580515204127000000	1580515205962135000
1580515204738000000	1580515206983780000
…	…
1580601595869000000	1580601595997115000
1580601596865000000	1580601596994060000
1580601597864000000	1580601597987786000
1580601598870000000	1580601598997068000
1580601599848000000	1580601599973647000
Converts back to the structured NumPy array.

data = df.to_numpy(structured=True)
data
array([(1580515202843000000, 1580515202979365000),
       (1580515203551000000, 1580515203943566000),
       (1580515203789000000, 1580515204875639000), ...,
       (1580601597864000000, 1580601597987786000),
       (1580601598870000000, 1580601598997068000),
       (1580601599848000000, 1580601599973647000)],
      dtype=[('exch_ts', '<i8'), ('local_ts', '<i8')])
Generates order latency. Order latency consists of two components: the latency until the order request reaches the exchange’s matching engine and the latency until the response arrives backto the localy. Order latency is not the same as feed latency and does not need to be proportional to feed latency. However, for simplicity, we model order latency to be proportional to feed latency using a multiplier and offset.

mul_entry = 4
offset_entry = 0

mul_resp = 3
offset_resp = 0

order_latency = np.zeros(len(data), dtype=[('req_ts', 'i8'), ('exch_ts', 'i8'), ('resp_ts', 'i8'), ('_padding', 'i8')])
for i, (exch_ts, local_ts) in enumerate(data):
    feed_latency = local_ts - exch_ts
    order_entry_latency = mul_entry * feed_latency + offset_entry
    order_resp_latency = mul_resp * feed_latency + offset_resp

    req_ts = local_ts
    order_exch_ts = req_ts + order_entry_latency
    resp_ts = order_exch_ts + order_resp_latency

    order_latency[i] = (req_ts, order_exch_ts, resp_ts, 0)

order_latency
array([(1580515202979365000, 1580515203524825000, 1580515203933920000, 0),
       (1580515203943566000, 1580515205513830000, 1580515206691528000, 0),
       (1580515204875639000, 1580515209222195000, 1580515212482112000, 0),
       ...,
       (1580601597987786000, 1580601598482930000, 1580601598854288000, 0),
       (1580601598997068000, 1580601599505340000, 1580601599886544000, 0),
       (1580601599973647000, 1580601600476235000, 1580601600853176000, 0)],
      dtype=[('req_ts', '<i8'), ('exch_ts', '<i8'), ('resp_ts', '<i8'), ('_padding', '<i8')])
df_order_latency = pl.DataFrame(order_latency)
df_order_latency
shape: (86_394, 4)
req_ts	exch_ts	resp_ts	_padding
i64	i64	i64	i64
1580515202979365000	1580515203524825000	1580515203933920000	0
1580515203943566000	1580515205513830000	1580515206691528000	0
1580515204875639000	1580515209222195000	1580515212482112000	0
1580515205962135000	1580515213302675000	1580515218808080000	0
1580515206983780000	1580515215966900000	1580515222704240000	0
…	…	…	…
1580601595997115000	1580601596509575000	1580601596893920000	0
1580601596994060000	1580601597510300000	1580601597897480000	0
1580601597987786000	1580601598482930000	1580601598854288000	0
1580601598997068000	1580601599505340000	1580601599886544000	0
1580601599973647000	1580601600476235000	1580601600853176000	0
Checks if latency has invalid negative values.

order_entry_latency = df_order_latency['exch_ts'] - df_order_latency['req_ts']
order_resp_latency = df_order_latency['resp_ts'] - df_order_latency['exch_ts']
(order_entry_latency <= 0).sum()
0
(order_resp_latency <= 0).sum()
0
Here, we wrap the entire process into a method with njit for increased speed.

import numpy as np
from numba import njit
import polars as pl
from hftbacktest import LOCAL_EVENT, EXCH_EVENT

@njit
def generate_order_latency_nb(data, order_latency, mul_entry, offset_entry, mul_resp, offset_resp):
    for i in range(len(data)):
        exch_ts = data[i].exch_ts
        local_ts = data[i].local_ts
        feed_latency = local_ts - exch_ts
        order_entry_latency = mul_entry * feed_latency + offset_entry
        order_resp_latency = mul_resp * feed_latency + offset_resp

        req_ts = local_ts
        order_exch_ts = req_ts + order_entry_latency
        resp_ts = order_exch_ts + order_resp_latency

        order_latency[i].req_ts = req_ts
        order_latency[i].exch_ts = order_exch_ts
        order_latency[i].resp_ts = resp_ts

def generate_order_latency(feed_file, output_file = None, mul_entry = 1, offset_entry = 0, mul_resp = 1, offset_resp = 0):
    data = np.load(feed_file)['data']
    df = pl.DataFrame(data)

    df = df.filter(
        (pl.col('ev') & EXCH_EVENT == EXCH_EVENT) & (pl.col('ev') & LOCAL_EVENT == LOCAL_EVENT)
    ).with_columns(
        pl.col('local_ts').alias('ts')
    ).group_by_dynamic(
        'ts', every='1000000000i'
    ).agg(
        pl.col('exch_ts').last(),
        pl.col('local_ts').last()
    ).drop('ts')

    data = df.to_numpy(structured=True)

    order_latency = np.zeros(len(data), dtype=[('req_ts', 'i8'), ('exch_ts', 'i8'), ('resp_ts', 'i8'), ('_padding', 'i8')])
    generate_order_latency_nb(data, order_latency, mul_entry, offset_entry, mul_resp, offset_resp)

    if output_file is not None:
        np.savez_compressed(output_file, data=order_latency)

    return order_latency
order_latency = generate_order_latency('btcusdt_20200201.npz', output_file='feed_latency_20200201.npz', mul_entry=4, mul_resp=3)
© Copyright 2024, nkaz001.

Built with Sphinx using a theme provided by Read the Docs.
Read the Docs
 latest